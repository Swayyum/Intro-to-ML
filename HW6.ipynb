{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMSlpieo0yCR6Bluv28Pm4k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swayyum/Intro-to-ML--4105/blob/main/HW6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PUMt_DdXqo22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d2b9c38-ec7f-47a4-9402-8fffc2367baa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/Intro to ML Collab/Datasets/Housing.csv'\n",
        "housing = pd.DataFrame(pd.read_csv(file_path))"
      ],
      "metadata": {
        "id": "cOOtikeBrIu3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making non-binary values binary\n",
        "yes_no_mapping = {'yes': 1, 'no': 0}\n",
        "furnishing_mapping = {'furnished': 1, 'semi-furnished': 0, 'unfurnished': 0}\n",
        "yes_no_columns = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
        "furnishing_columns = ['furnishingstatus']\n",
        "housing[yes_no_columns] = housing[yes_no_columns].applymap(yes_no_mapping.get)\n",
        "housing[furnishing_columns] = housing[furnishing_columns].applymap(furnishing_mapping.get)"
      ],
      "metadata": {
        "id": "cM0tU9vZzZDR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jFLc34FczsWY",
        "outputId": "bbc7e9c4-d819-49e6-ae86-8c9f36e32a6b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      price  area  bedrooms  bathrooms  stories  mainroad  guestroom  \\\n",
              "0  13300000  7420         4          2        3         1          0   \n",
              "1  12250000  8960         4          4        4         1          0   \n",
              "2  12250000  9960         3          2        2         1          0   \n",
              "3  12215000  7500         4          2        2         1          0   \n",
              "4  11410000  7420         4          1        2         1          1   \n",
              "\n",
              "   basement  hotwaterheating  airconditioning  parking  prefarea  \\\n",
              "0         0                0                1        2         1   \n",
              "1         0                0                1        3         0   \n",
              "2         1                0                0        2         1   \n",
              "3         1                0                1        3         1   \n",
              "4         1                0                1        2         0   \n",
              "\n",
              "   furnishingstatus  \n",
              "0                 1  \n",
              "1                 1  \n",
              "2                 0  \n",
              "3                 1  \n",
              "4                 1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f134e11-5e51-48c1-bfda-298db1e94e47\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>area</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>stories</th>\n",
              "      <th>mainroad</th>\n",
              "      <th>guestroom</th>\n",
              "      <th>basement</th>\n",
              "      <th>hotwaterheating</th>\n",
              "      <th>airconditioning</th>\n",
              "      <th>parking</th>\n",
              "      <th>prefarea</th>\n",
              "      <th>furnishingstatus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13300000</td>\n",
              "      <td>7420</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12250000</td>\n",
              "      <td>8960</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12250000</td>\n",
              "      <td>9960</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12215000</td>\n",
              "      <td>7500</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11410000</td>\n",
              "      <td>7420</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f134e11-5e51-48c1-bfda-298db1e94e47')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1f134e11-5e51-48c1-bfda-298db1e94e47 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1f134e11-5e51-48c1-bfda-298db1e94e47');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c89f82fe-b654-4d0c-b38a-43fa54f60dab\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c89f82fe-b654-4d0c-b38a-43fa54f60dab')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c89f82fe-b654-4d0c-b38a-43fa54f60dab button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X1 = housing[['area', 'bedrooms', 'bathrooms', 'stories', 'mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'parking', 'prefarea', 'furnishingstatus']]\n",
        "X1 = housing[['area', 'bedrooms', 'bathrooms', 'stories', 'mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'parking', 'prefarea']]\n",
        "y1 = housing['price'].values.reshape(-1,1)\n",
        "#y1 = housing['price']"
      ],
      "metadata": {
        "id": "5ADLI7x2sFPu"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"nan:\", housing.isna().sum().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZRzu57prpT3",
        "outputId": "851f8a0f-0667-42ad-e2b0-7cc1fef03c88"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nan: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X1_train, X1_val, y1_train, y1_val = train_test_split(X1, y1, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "XTFFV7Exs_ic"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X1_train_scaled = scaler.fit_transform(X1_train)\n",
        "X1_val_scaled = scaler.transform(X1_val)\n",
        "\n",
        "X_train_tensor = torch.tensor(X1_train_scaled, dtype = torch.float32)\n",
        "X_val_tensor = torch.tensor(X1_val_scaled, dtype = torch.float32)"
      ],
      "metadata": {
        "id": "grhVckq4n0Co"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_tensor = torch.tensor(y1_train, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y1_val, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "dburD21An8Dt"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1a: 1 hidden layer"
      ],
      "metadata": {
        "id": "vNFMNlfhv7As"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(X1_train.shape[1], 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 1)\n",
        ")\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "MNBgZJN3rXvV"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, model, loss_fn, X_train, y_train, X_val, y_val):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        y_pred = model(X_train)\n",
        "        loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            y_val_pred = model(X_val)\n",
        "            val_loss = loss_fn(y_val_pred, y_val)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.detach().item())\n",
        "        val_losses.append(val_loss.detach().item())\n",
        "\n",
        "\n",
        "        if epoch == 1 or epoch % 100 == 0:\n",
        "            print(f\"Epoch {epoch}, Training loss {loss.item():.4f}, Validation loss {val_loss.item():.4f}\")\n",
        "\n",
        "    return train_losses, val_losses\n",
        "\n",
        "# Model\n",
        "train_losses1, val_losses1 = training_loop(\n",
        "    n_epochs = 50000,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    X_train = X_train_tensor,\n",
        "    y_train = y_train_tensor,\n",
        "    X_val = X_val_tensor,\n",
        "    y_val = y_val_tensor\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUIPnT8fralu",
        "outputId": "281537e0-0a66-4886-f123-3d09f0f8ec75"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 26469982011392.0000, Validation loss 25189244993536.0000\n",
            "Epoch 100, Training loss 26341837635584.0000, Validation loss 25062839156736.0000\n",
            "Epoch 200, Training loss 25819260911616.0000, Validation loss 24550603489280.0000\n",
            "Epoch 300, Training loss 24912076996608.0000, Validation loss 23661102759936.0000\n",
            "Epoch 400, Training loss 23681107492864.0000, Validation loss 22455427006464.0000\n",
            "Epoch 500, Training loss 22193366892544.0000, Validation loss 21002111156224.0000\n",
            "Epoch 600, Training loss 20519705378816.0000, Validation loss 19372185747456.0000\n",
            "Epoch 700, Training loss 18731572920320.0000, Validation loss 17632432488448.0000\n",
            "Epoch 800, Training loss 16891405926400.0000, Validation loss 15842655862784.0000\n",
            "Epoch 900, Training loss 15048747515904.0000, Validation loss 14055258456064.0000\n",
            "Epoch 1000, Training loss 13253836013568.0000, Validation loss 12324872126464.0000\n",
            "Epoch 1100, Training loss 11551768576000.0000, Validation loss 10698518167552.0000\n",
            "Epoch 1200, Training loss 9976319836160.0000, Validation loss 9201603575808.0000\n",
            "Epoch 1300, Training loss 8551576109056.0000, Validation loss 7858399739904.0000\n",
            "Epoch 1400, Training loss 7291197194240.0000, Validation loss 6683996717056.0000\n",
            "Epoch 1500, Training loss 6204200321024.0000, Validation loss 5681093541888.0000\n",
            "Epoch 1600, Training loss 5291064164352.0000, Validation loss 4844405915648.0000\n",
            "Epoch 1700, Training loss 4547722870784.0000, Validation loss 4162688122880.0000\n",
            "Epoch 1800, Training loss 3958709944320.0000, Validation loss 3621570478080.0000\n",
            "Epoch 1900, Training loss 3498404478976.0000, Validation loss 3197527916544.0000\n",
            "Epoch 2000, Training loss 3141138120704.0000, Validation loss 2864806363136.0000\n",
            "Epoch 2100, Training loss 2864942678016.0000, Validation loss 2605992902656.0000\n",
            "Epoch 2200, Training loss 2649405521920.0000, Validation loss 2398611308544.0000\n",
            "Epoch 2300, Training loss 2473119186944.0000, Validation loss 2227990953984.0000\n",
            "Epoch 2400, Training loss 2326537699328.0000, Validation loss 2085035311104.0000\n",
            "Epoch 2500, Training loss 2205273554944.0000, Validation loss 1964588793856.0000\n",
            "Epoch 2600, Training loss 2099351912448.0000, Validation loss 1863167115264.0000\n",
            "Epoch 2700, Training loss 2004358791168.0000, Validation loss 1773035978752.0000\n",
            "Epoch 2800, Training loss 1918226530304.0000, Validation loss 1693967187968.0000\n",
            "Epoch 2900, Training loss 1838977777664.0000, Validation loss 1624099782656.0000\n",
            "Epoch 3000, Training loss 1766193889280.0000, Validation loss 1561445662720.0000\n",
            "Epoch 3100, Training loss 1699556622336.0000, Validation loss 1503379587072.0000\n",
            "Epoch 3200, Training loss 1637439504384.0000, Validation loss 1452123488256.0000\n",
            "Epoch 3300, Training loss 1580198395904.0000, Validation loss 1404461907968.0000\n",
            "Epoch 3400, Training loss 1529251102720.0000, Validation loss 1361340530688.0000\n",
            "Epoch 3500, Training loss 1484351864832.0000, Validation loss 1325864714240.0000\n",
            "Epoch 3600, Training loss 1443925721088.0000, Validation loss 1296558587904.0000\n",
            "Epoch 3700, Training loss 1408156434432.0000, Validation loss 1271127867392.0000\n",
            "Epoch 3800, Training loss 1374591909888.0000, Validation loss 1250284797952.0000\n",
            "Epoch 3900, Training loss 1344398032896.0000, Validation loss 1232777248768.0000\n",
            "Epoch 4000, Training loss 1315967598592.0000, Validation loss 1215795298304.0000\n",
            "Epoch 4100, Training loss 1290576330752.0000, Validation loss 1200821108736.0000\n",
            "Epoch 4200, Training loss 1267788283904.0000, Validation loss 1188237672448.0000\n",
            "Epoch 4300, Training loss 1247041552384.0000, Validation loss 1176996675584.0000\n",
            "Epoch 4400, Training loss 1228620169216.0000, Validation loss 1165447528448.0000\n",
            "Epoch 4500, Training loss 1210766458880.0000, Validation loss 1153736638464.0000\n",
            "Epoch 4600, Training loss 1193993043968.0000, Validation loss 1144532762624.0000\n",
            "Epoch 4700, Training loss 1178938507264.0000, Validation loss 1137261805568.0000\n",
            "Epoch 4800, Training loss 1164155158528.0000, Validation loss 1129959915520.0000\n",
            "Epoch 4900, Training loss 1149680091136.0000, Validation loss 1123307618304.0000\n",
            "Epoch 5000, Training loss 1136485990400.0000, Validation loss 1118905565184.0000\n",
            "Epoch 5100, Training loss 1124013178880.0000, Validation loss 1115655897088.0000\n",
            "Epoch 5200, Training loss 1111665410048.0000, Validation loss 1112601919488.0000\n",
            "Epoch 5300, Training loss 1099980210176.0000, Validation loss 1110115876864.0000\n",
            "Epoch 5400, Training loss 1088816545792.0000, Validation loss 1109162328064.0000\n",
            "Epoch 5500, Training loss 1078116810752.0000, Validation loss 1111268392960.0000\n",
            "Epoch 5600, Training loss 1068741165056.0000, Validation loss 1112837980160.0000\n",
            "Epoch 5700, Training loss 1060440899584.0000, Validation loss 1114034798592.0000\n",
            "Epoch 5800, Training loss 1052594733056.0000, Validation loss 1115120336896.0000\n",
            "Epoch 5900, Training loss 1045094596608.0000, Validation loss 1115403714560.0000\n",
            "Epoch 6000, Training loss 1037927186432.0000, Validation loss 1115557330944.0000\n",
            "Epoch 6100, Training loss 1031000883200.0000, Validation loss 1115803222016.0000\n",
            "Epoch 6200, Training loss 1024555155456.0000, Validation loss 1115259797504.0000\n",
            "Epoch 6300, Training loss 1018814726144.0000, Validation loss 1112989761536.0000\n",
            "Epoch 6400, Training loss 1013657239552.0000, Validation loss 1110775037952.0000\n",
            "Epoch 6500, Training loss 1008667525120.0000, Validation loss 1109499969536.0000\n",
            "Epoch 6600, Training loss 1003643011072.0000, Validation loss 1108937146368.0000\n",
            "Epoch 6700, Training loss 998924288000.0000, Validation loss 1108422688768.0000\n",
            "Epoch 6800, Training loss 994451849216.0000, Validation loss 1107800752128.0000\n",
            "Epoch 6900, Training loss 989867409408.0000, Validation loss 1106868043776.0000\n",
            "Epoch 7000, Training loss 984834768896.0000, Validation loss 1106067193856.0000\n",
            "Epoch 7100, Training loss 980148027392.0000, Validation loss 1103815245824.0000\n",
            "Epoch 7200, Training loss 975630368768.0000, Validation loss 1100594413568.0000\n",
            "Epoch 7300, Training loss 970826711040.0000, Validation loss 1099108712448.0000\n",
            "Epoch 7400, Training loss 966048153600.0000, Validation loss 1098346528768.0000\n",
            "Epoch 7500, Training loss 960866418688.0000, Validation loss 1099399364608.0000\n",
            "Epoch 7600, Training loss 955947810816.0000, Validation loss 1097384460288.0000\n",
            "Epoch 7700, Training loss 951858888704.0000, Validation loss 1096088748032.0000\n",
            "Epoch 7800, Training loss 948309655552.0000, Validation loss 1094985318400.0000\n",
            "Epoch 7900, Training loss 945119887360.0000, Validation loss 1093756911616.0000\n",
            "Epoch 8000, Training loss 942273396736.0000, Validation loss 1091557392384.0000\n",
            "Epoch 8100, Training loss 939154866176.0000, Validation loss 1089922072576.0000\n",
            "Epoch 8200, Training loss 936286945280.0000, Validation loss 1088922910720.0000\n",
            "Epoch 8300, Training loss 933605015552.0000, Validation loss 1087977619456.0000\n",
            "Epoch 8400, Training loss 931095838720.0000, Validation loss 1087313870848.0000\n",
            "Epoch 8500, Training loss 928781565952.0000, Validation loss 1087176572928.0000\n",
            "Epoch 8600, Training loss 926685462528.0000, Validation loss 1086844436480.0000\n",
            "Epoch 8700, Training loss 924489940992.0000, Validation loss 1086924193792.0000\n",
            "Epoch 8800, Training loss 922207977472.0000, Validation loss 1087827476480.0000\n",
            "Epoch 8900, Training loss 920042668032.0000, Validation loss 1087109201920.0000\n",
            "Epoch 9000, Training loss 917884764160.0000, Validation loss 1086043979776.0000\n",
            "Epoch 9100, Training loss 915681968128.0000, Validation loss 1085044424704.0000\n",
            "Epoch 9200, Training loss 913375494144.0000, Validation loss 1085974183936.0000\n",
            "Epoch 9300, Training loss 910984282112.0000, Validation loss 1087512838144.0000\n",
            "Epoch 9400, Training loss 908614369280.0000, Validation loss 1089437827072.0000\n",
            "Epoch 9500, Training loss 905979035648.0000, Validation loss 1092553080832.0000\n",
            "Epoch 9600, Training loss 903504265216.0000, Validation loss 1095174127616.0000\n",
            "Epoch 9700, Training loss 900828758016.0000, Validation loss 1097939484672.0000\n",
            "Epoch 9800, Training loss 898318204928.0000, Validation loss 1099645583360.0000\n",
            "Epoch 9900, Training loss 895887933440.0000, Validation loss 1099456905216.0000\n",
            "Epoch 10000, Training loss 893739073536.0000, Validation loss 1100211814400.0000\n",
            "Epoch 10100, Training loss 891798224896.0000, Validation loss 1102007238656.0000\n",
            "Epoch 10200, Training loss 889662210048.0000, Validation loss 1104612032512.0000\n",
            "Epoch 10300, Training loss 887751639040.0000, Validation loss 1105375526912.0000\n",
            "Epoch 10400, Training loss 885858631680.0000, Validation loss 1106326192128.0000\n",
            "Epoch 10500, Training loss 883736903680.0000, Validation loss 1107853312000.0000\n",
            "Epoch 10600, Training loss 882145755136.0000, Validation loss 1108212711424.0000\n",
            "Epoch 10700, Training loss 880856072192.0000, Validation loss 1109335998464.0000\n",
            "Epoch 10800, Training loss 879638413312.0000, Validation loss 1110906765312.0000\n",
            "Epoch 10900, Training loss 878304886784.0000, Validation loss 1112144740352.0000\n",
            "Epoch 11000, Training loss 877156564992.0000, Validation loss 1112154046464.0000\n",
            "Epoch 11100, Training loss 876003065856.0000, Validation loss 1111982342144.0000\n",
            "Epoch 11200, Training loss 874872045568.0000, Validation loss 1111793336320.0000\n",
            "Epoch 11300, Training loss 873865740288.0000, Validation loss 1111814832128.0000\n",
            "Epoch 11400, Training loss 872949481472.0000, Validation loss 1112903909376.0000\n",
            "Epoch 11500, Training loss 872112259072.0000, Validation loss 1112556568576.0000\n",
            "Epoch 11600, Training loss 870990675968.0000, Validation loss 1110544875520.0000\n",
            "Epoch 11700, Training loss 869920407552.0000, Validation loss 1107755270144.0000\n",
            "Epoch 11800, Training loss 868913250304.0000, Validation loss 1106382028800.0000\n",
            "Epoch 11900, Training loss 867898621952.0000, Validation loss 1107074744320.0000\n",
            "Epoch 12000, Training loss 866940551168.0000, Validation loss 1107519340544.0000\n",
            "Epoch 12100, Training loss 865689010176.0000, Validation loss 1106926239744.0000\n",
            "Epoch 12200, Training loss 864582434816.0000, Validation loss 1107138445312.0000\n",
            "Epoch 12300, Training loss 863569182720.0000, Validation loss 1107825000448.0000\n",
            "Epoch 12400, Training loss 862659870720.0000, Validation loss 1108880785408.0000\n",
            "Epoch 12500, Training loss 861841981440.0000, Validation loss 1109754904576.0000\n",
            "Epoch 12600, Training loss 861071802368.0000, Validation loss 1110218113024.0000\n",
            "Epoch 12700, Training loss 860367159296.0000, Validation loss 1111601053696.0000\n",
            "Epoch 12800, Training loss 859494088704.0000, Validation loss 1113650888704.0000\n",
            "Epoch 12900, Training loss 858228391936.0000, Validation loss 1113045467136.0000\n",
            "Epoch 13000, Training loss 857264619520.0000, Validation loss 1112608473088.0000\n",
            "Epoch 13100, Training loss 856241733632.0000, Validation loss 1113637257216.0000\n",
            "Epoch 13200, Training loss 855294148608.0000, Validation loss 1114507182080.0000\n",
            "Epoch 13300, Training loss 854563553280.0000, Validation loss 1114104528896.0000\n",
            "Epoch 13400, Training loss 854004072448.0000, Validation loss 1112796954624.0000\n",
            "Epoch 13500, Training loss 853099675648.0000, Validation loss 1112686329856.0000\n",
            "Epoch 13600, Training loss 852187217920.0000, Validation loss 1112581865472.0000\n",
            "Epoch 13700, Training loss 851478642688.0000, Validation loss 1113304072192.0000\n",
            "Epoch 13800, Training loss 850699354112.0000, Validation loss 1113869385728.0000\n",
            "Epoch 13900, Training loss 849706418176.0000, Validation loss 1115720384512.0000\n",
            "Epoch 14000, Training loss 848810737664.0000, Validation loss 1118043635712.0000\n",
            "Epoch 14100, Training loss 847737978880.0000, Validation loss 1120092291072.0000\n",
            "Epoch 14200, Training loss 846712078336.0000, Validation loss 1122413576192.0000\n",
            "Epoch 14300, Training loss 845602095104.0000, Validation loss 1123712499712.0000\n",
            "Epoch 14400, Training loss 844448071680.0000, Validation loss 1125324816384.0000\n",
            "Epoch 14500, Training loss 843471716352.0000, Validation loss 1127120109568.0000\n",
            "Epoch 14600, Training loss 842643079168.0000, Validation loss 1128079032320.0000\n",
            "Epoch 14700, Training loss 841913401344.0000, Validation loss 1127873511424.0000\n",
            "Epoch 14800, Training loss 841160916992.0000, Validation loss 1128213250048.0000\n",
            "Epoch 14900, Training loss 840443428864.0000, Validation loss 1128071168000.0000\n",
            "Epoch 15000, Training loss 839901773824.0000, Validation loss 1129284632576.0000\n",
            "Epoch 15100, Training loss 839400947712.0000, Validation loss 1130026369024.0000\n",
            "Epoch 15200, Training loss 838909755392.0000, Validation loss 1130909532160.0000\n",
            "Epoch 15300, Training loss 838417514496.0000, Validation loss 1131933990912.0000\n",
            "Epoch 15400, Training loss 837720670208.0000, Validation loss 1133050462208.0000\n",
            "Epoch 15500, Training loss 836946558976.0000, Validation loss 1134527774720.0000\n",
            "Epoch 15600, Training loss 836142628864.0000, Validation loss 1136078094336.0000\n",
            "Epoch 15700, Training loss 835388768256.0000, Validation loss 1138294915072.0000\n",
            "Epoch 15800, Training loss 834669772800.0000, Validation loss 1140756578304.0000\n",
            "Epoch 15900, Training loss 833976139776.0000, Validation loss 1143331618816.0000\n",
            "Epoch 16000, Training loss 833283096576.0000, Validation loss 1147505737728.0000\n",
            "Epoch 16100, Training loss 832779321344.0000, Validation loss 1151231590400.0000\n",
            "Epoch 16200, Training loss 832379420672.0000, Validation loss 1154229862400.0000\n",
            "Epoch 16300, Training loss 832027688960.0000, Validation loss 1157386993664.0000\n",
            "Epoch 16400, Training loss 831664619520.0000, Validation loss 1160618049536.0000\n",
            "Epoch 16500, Training loss 831248793600.0000, Validation loss 1163022303232.0000\n",
            "Epoch 16600, Training loss 830818615296.0000, Validation loss 1164441419776.0000\n",
            "Epoch 16700, Training loss 830364123136.0000, Validation loss 1163781341184.0000\n",
            "Epoch 16800, Training loss 830008590336.0000, Validation loss 1162293149696.0000\n",
            "Epoch 16900, Training loss 829610459136.0000, Validation loss 1160702722048.0000\n",
            "Epoch 17000, Training loss 829197647872.0000, Validation loss 1160738111488.0000\n",
            "Epoch 17100, Training loss 828740534272.0000, Validation loss 1160776777728.0000\n",
            "Epoch 17200, Training loss 828351643648.0000, Validation loss 1160885960704.0000\n",
            "Epoch 17300, Training loss 827683110912.0000, Validation loss 1161229631488.0000\n",
            "Epoch 17400, Training loss 827125989376.0000, Validation loss 1162272309248.0000\n",
            "Epoch 17500, Training loss 826684538880.0000, Validation loss 1163811618816.0000\n",
            "Epoch 17600, Training loss 826376519680.0000, Validation loss 1165032947712.0000\n",
            "Epoch 17700, Training loss 826000539648.0000, Validation loss 1165744013312.0000\n",
            "Epoch 17800, Training loss 825435619328.0000, Validation loss 1169710776320.0000\n",
            "Epoch 17900, Training loss 825023660032.0000, Validation loss 1173478309888.0000\n",
            "Epoch 18000, Training loss 824772853760.0000, Validation loss 1175437443072.0000\n",
            "Epoch 18100, Training loss 824593088512.0000, Validation loss 1176489164800.0000\n",
            "Epoch 18200, Training loss 824452644864.0000, Validation loss 1176911216640.0000\n",
            "Epoch 18300, Training loss 824137351168.0000, Validation loss 1176175640576.0000\n",
            "Epoch 18400, Training loss 823891853312.0000, Validation loss 1178204504064.0000\n",
            "Epoch 18500, Training loss 823687970816.0000, Validation loss 1179316256768.0000\n",
            "Epoch 18600, Training loss 823378509824.0000, Validation loss 1179090550784.0000\n",
            "Epoch 18700, Training loss 822750281728.0000, Validation loss 1178257063936.0000\n",
            "Epoch 18800, Training loss 821473312768.0000, Validation loss 1175039901696.0000\n",
            "Epoch 18900, Training loss 820136378368.0000, Validation loss 1171862192128.0000\n",
            "Epoch 19000, Training loss 819120373760.0000, Validation loss 1170345689088.0000\n",
            "Epoch 19100, Training loss 818246844416.0000, Validation loss 1168088891392.0000\n",
            "Epoch 19200, Training loss 817317347328.0000, Validation loss 1165911785472.0000\n",
            "Epoch 19300, Training loss 816459677696.0000, Validation loss 1165355253760.0000\n",
            "Epoch 19400, Training loss 814760329216.0000, Validation loss 1165181976576.0000\n",
            "Epoch 19500, Training loss 813687439360.0000, Validation loss 1165261144064.0000\n",
            "Epoch 19600, Training loss 812430000128.0000, Validation loss 1164974489600.0000\n",
            "Epoch 19700, Training loss 810613145600.0000, Validation loss 1165653049344.0000\n",
            "Epoch 19800, Training loss 808542011392.0000, Validation loss 1170822922240.0000\n",
            "Epoch 19900, Training loss 806451675136.0000, Validation loss 1174850109440.0000\n",
            "Epoch 20000, Training loss 804521771008.0000, Validation loss 1178846887936.0000\n",
            "Epoch 20100, Training loss 802620178432.0000, Validation loss 1182422794240.0000\n",
            "Epoch 20200, Training loss 800697942016.0000, Validation loss 1186389557248.0000\n",
            "Epoch 20300, Training loss 798911627264.0000, Validation loss 1189974114304.0000\n",
            "Epoch 20400, Training loss 797025959936.0000, Validation loss 1190571409408.0000\n",
            "Epoch 20500, Training loss 795341094912.0000, Validation loss 1194767548416.0000\n",
            "Epoch 20600, Training loss 793680805888.0000, Validation loss 1199257288704.0000\n",
            "Epoch 20700, Training loss 792093982720.0000, Validation loss 1202534612992.0000\n",
            "Epoch 20800, Training loss 790284402688.0000, Validation loss 1207784701952.0000\n",
            "Epoch 20900, Training loss 788319109120.0000, Validation loss 1215066013696.0000\n",
            "Epoch 21000, Training loss 786103861248.0000, Validation loss 1219392962560.0000\n",
            "Epoch 21100, Training loss 784249520128.0000, Validation loss 1227363713024.0000\n",
            "Epoch 21200, Training loss 782295040000.0000, Validation loss 1234786975744.0000\n",
            "Epoch 21300, Training loss 779926765568.0000, Validation loss 1243551367168.0000\n",
            "Epoch 21400, Training loss 777704308736.0000, Validation loss 1258183589888.0000\n",
            "Epoch 21500, Training loss 776106999808.0000, Validation loss 1267666386944.0000\n",
            "Epoch 21600, Training loss 774585778176.0000, Validation loss 1276939337728.0000\n",
            "Epoch 21700, Training loss 773118427136.0000, Validation loss 1283860332544.0000\n",
            "Epoch 21800, Training loss 771744595968.0000, Validation loss 1291202854912.0000\n",
            "Epoch 21900, Training loss 770436431872.0000, Validation loss 1296527917056.0000\n",
            "Epoch 22000, Training loss 769060110336.0000, Validation loss 1301526872064.0000\n",
            "Epoch 22100, Training loss 766848925696.0000, Validation loss 1307762098176.0000\n",
            "Epoch 22200, Training loss 764454830080.0000, Validation loss 1305974145024.0000\n",
            "Epoch 22300, Training loss 762884128768.0000, Validation loss 1308258205696.0000\n",
            "Epoch 22400, Training loss 761545490432.0000, Validation loss 1310294540288.0000\n",
            "Epoch 22500, Training loss 760318394368.0000, Validation loss 1313163313152.0000\n",
            "Epoch 22600, Training loss 759167778816.0000, Validation loss 1316228169728.0000\n",
            "Epoch 22700, Training loss 757965848576.0000, Validation loss 1318775160832.0000\n",
            "Epoch 22800, Training loss 756803108864.0000, Validation loss 1321364619264.0000\n",
            "Epoch 22900, Training loss 755084492800.0000, Validation loss 1327511896064.0000\n",
            "Epoch 23000, Training loss 753014341632.0000, Validation loss 1334318727168.0000\n",
            "Epoch 23100, Training loss 751410937856.0000, Validation loss 1341189783552.0000\n",
            "Epoch 23200, Training loss 748762824704.0000, Validation loss 1350102941696.0000\n",
            "Epoch 23300, Training loss 745793454080.0000, Validation loss 1356691668992.0000\n",
            "Epoch 23400, Training loss 741668552704.0000, Validation loss 1363111051264.0000\n",
            "Epoch 23500, Training loss 736786579456.0000, Validation loss 1368491687936.0000\n",
            "Epoch 23600, Training loss 733127835648.0000, Validation loss 1367913791488.0000\n",
            "Epoch 23700, Training loss 729120112640.0000, Validation loss 1361933107200.0000\n",
            "Epoch 23800, Training loss 725956362240.0000, Validation loss 1363562201088.0000\n",
            "Epoch 23900, Training loss 723113082880.0000, Validation loss 1364877770752.0000\n",
            "Epoch 24000, Training loss 720723443712.0000, Validation loss 1366752493568.0000\n",
            "Epoch 24100, Training loss 718288519168.0000, Validation loss 1374149410816.0000\n",
            "Epoch 24200, Training loss 715983224832.0000, Validation loss 1378397585408.0000\n",
            "Epoch 24300, Training loss 713880829952.0000, Validation loss 1379989585920.0000\n",
            "Epoch 24400, Training loss 711615905792.0000, Validation loss 1378794995712.0000\n",
            "Epoch 24500, Training loss 708623859712.0000, Validation loss 1375931334656.0000\n",
            "Epoch 24600, Training loss 705280278528.0000, Validation loss 1374806343680.0000\n",
            "Epoch 24700, Training loss 702174003200.0000, Validation loss 1382740000768.0000\n",
            "Epoch 24800, Training loss 699026636800.0000, Validation loss 1387065507840.0000\n",
            "Epoch 24900, Training loss 696265342976.0000, Validation loss 1395092881408.0000\n",
            "Epoch 25000, Training loss 693862793216.0000, Validation loss 1402603175936.0000\n",
            "Epoch 25100, Training loss 691860537344.0000, Validation loss 1410312306688.0000\n",
            "Epoch 25200, Training loss 690068914176.0000, Validation loss 1416937996288.0000\n",
            "Epoch 25300, Training loss 688244064256.0000, Validation loss 1424495476736.0000\n",
            "Epoch 25400, Training loss 686539407360.0000, Validation loss 1431971561472.0000\n",
            "Epoch 25500, Training loss 684956647424.0000, Validation loss 1437303177216.0000\n",
            "Epoch 25600, Training loss 683393875968.0000, Validation loss 1441418969088.0000\n",
            "Epoch 25700, Training loss 682002153472.0000, Validation loss 1446367461376.0000\n",
            "Epoch 25800, Training loss 680703688704.0000, Validation loss 1451943395328.0000\n",
            "Epoch 25900, Training loss 679326318592.0000, Validation loss 1456802496512.0000\n",
            "Epoch 26000, Training loss 678057082880.0000, Validation loss 1462065692672.0000\n",
            "Epoch 26100, Training loss 676373463040.0000, Validation loss 1464827772928.0000\n",
            "Epoch 26200, Training loss 674778644480.0000, Validation loss 1467457470464.0000\n",
            "Epoch 26300, Training loss 673330102272.0000, Validation loss 1471082659840.0000\n",
            "Epoch 26400, Training loss 671930974208.0000, Validation loss 1474970910720.0000\n",
            "Epoch 26500, Training loss 670278221824.0000, Validation loss 1479164297216.0000\n",
            "Epoch 26600, Training loss 668304146432.0000, Validation loss 1482032414720.0000\n",
            "Epoch 26700, Training loss 666463305728.0000, Validation loss 1486783512576.0000\n",
            "Epoch 26800, Training loss 664809635840.0000, Validation loss 1492894613504.0000\n",
            "Epoch 26900, Training loss 663110221824.0000, Validation loss 1500416966656.0000\n",
            "Epoch 27000, Training loss 661071724544.0000, Validation loss 1506643410944.0000\n",
            "Epoch 27100, Training loss 659073138688.0000, Validation loss 1509664882688.0000\n",
            "Epoch 27200, Training loss 656483221504.0000, Validation loss 1514575888384.0000\n",
            "Epoch 27300, Training loss 653326548992.0000, Validation loss 1518808727552.0000\n",
            "Epoch 27400, Training loss 650742136832.0000, Validation loss 1524927954944.0000\n",
            "Epoch 27500, Training loss 648080392192.0000, Validation loss 1534026579968.0000\n",
            "Epoch 27600, Training loss 645082251264.0000, Validation loss 1543249199104.0000\n",
            "Epoch 27700, Training loss 641926955008.0000, Validation loss 1550463401984.0000\n",
            "Epoch 27800, Training loss 639009357824.0000, Validation loss 1558571384832.0000\n",
            "Epoch 27900, Training loss 636135669760.0000, Validation loss 1565527900160.0000\n",
            "Epoch 28000, Training loss 633171410944.0000, Validation loss 1570174271488.0000\n",
            "Epoch 28100, Training loss 630308667392.0000, Validation loss 1573763153920.0000\n",
            "Epoch 28200, Training loss 627502481408.0000, Validation loss 1577160671232.0000\n",
            "Epoch 28300, Training loss 624695967744.0000, Validation loss 1581001998336.0000\n",
            "Epoch 28400, Training loss 621962657792.0000, Validation loss 1586181046272.0000\n",
            "Epoch 28500, Training loss 618871980032.0000, Validation loss 1588410974208.0000\n",
            "Epoch 28600, Training loss 615763214336.0000, Validation loss 1591500734464.0000\n",
            "Epoch 28700, Training loss 612208803840.0000, Validation loss 1592354144256.0000\n",
            "Epoch 28800, Training loss 608174931968.0000, Validation loss 1593846005760.0000\n",
            "Epoch 28900, Training loss 604297101312.0000, Validation loss 1595902525440.0000\n",
            "Epoch 29000, Training loss 600049123328.0000, Validation loss 1600227901440.0000\n",
            "Epoch 29100, Training loss 595120881664.0000, Validation loss 1603524100096.0000\n",
            "Epoch 29200, Training loss 590441742336.0000, Validation loss 1603315826688.0000\n",
            "Epoch 29300, Training loss 586134257664.0000, Validation loss 1602393473024.0000\n",
            "Epoch 29400, Training loss 582151634944.0000, Validation loss 1604286939136.0000\n",
            "Epoch 29500, Training loss 578484961280.0000, Validation loss 1606533251072.0000\n",
            "Epoch 29600, Training loss 574798888960.0000, Validation loss 1607829684224.0000\n",
            "Epoch 29700, Training loss 571312898048.0000, Validation loss 1614538866688.0000\n",
            "Epoch 29800, Training loss 567950180352.0000, Validation loss 1623303651328.0000\n",
            "Epoch 29900, Training loss 564853211136.0000, Validation loss 1632825507840.0000\n",
            "Epoch 30000, Training loss 561661673472.0000, Validation loss 1642972971008.0000\n",
            "Epoch 30100, Training loss 558604484608.0000, Validation loss 1650721161216.0000\n",
            "Epoch 30200, Training loss 555488706560.0000, Validation loss 1658782482432.0000\n",
            "Epoch 30300, Training loss 552424177664.0000, Validation loss 1668882628608.0000\n",
            "Epoch 30400, Training loss 549107924992.0000, Validation loss 1681605918720.0000\n",
            "Epoch 30500, Training loss 545328693248.0000, Validation loss 1695896961024.0000\n",
            "Epoch 30600, Training loss 541801185280.0000, Validation loss 1710438088704.0000\n",
            "Epoch 30700, Training loss 538313785344.0000, Validation loss 1724325167104.0000\n",
            "Epoch 30800, Training loss 534352297984.0000, Validation loss 1735027326976.0000\n",
            "Epoch 30900, Training loss 530343723008.0000, Validation loss 1745852956672.0000\n",
            "Epoch 31000, Training loss 526696415232.0000, Validation loss 1758369546240.0000\n",
            "Epoch 31100, Training loss 523151048704.0000, Validation loss 1772911067136.0000\n",
            "Epoch 31200, Training loss 518876168192.0000, Validation loss 1788966600704.0000\n",
            "Epoch 31300, Training loss 514454290432.0000, Validation loss 1798354894848.0000\n",
            "Epoch 31400, Training loss 509873127424.0000, Validation loss 1822538072064.0000\n",
            "Epoch 31500, Training loss 505665421312.0000, Validation loss 1846156984320.0000\n",
            "Epoch 31600, Training loss 501564014592.0000, Validation loss 1869747585024.0000\n",
            "Epoch 31700, Training loss 496963911680.0000, Validation loss 1889024081920.0000\n",
            "Epoch 31800, Training loss 492914900992.0000, Validation loss 1909052669952.0000\n",
            "Epoch 31900, Training loss 488506687488.0000, Validation loss 1927123173376.0000\n",
            "Epoch 32000, Training loss 484571709440.0000, Validation loss 1944583798784.0000\n",
            "Epoch 32100, Training loss 480693780480.0000, Validation loss 1954758656000.0000\n",
            "Epoch 32200, Training loss 476334817280.0000, Validation loss 1963250417664.0000\n",
            "Epoch 32300, Training loss 472236392448.0000, Validation loss 1975907254272.0000\n",
            "Epoch 32400, Training loss 468836417536.0000, Validation loss 1988137058304.0000\n",
            "Epoch 32500, Training loss 465654120448.0000, Validation loss 2002987122688.0000\n",
            "Epoch 32600, Training loss 462246608896.0000, Validation loss 2011537604608.0000\n",
            "Epoch 32700, Training loss 458602512384.0000, Validation loss 2019846127616.0000\n",
            "Epoch 32800, Training loss 455074906112.0000, Validation loss 2028735299584.0000\n",
            "Epoch 32900, Training loss 451812196352.0000, Validation loss 2042774290432.0000\n",
            "Epoch 33000, Training loss 448993361920.0000, Validation loss 2058818420736.0000\n",
            "Epoch 33100, Training loss 446374248448.0000, Validation loss 2075059290112.0000\n",
            "Epoch 33200, Training loss 443959541760.0000, Validation loss 2092490948608.0000\n",
            "Epoch 33300, Training loss 441628590080.0000, Validation loss 2112900431872.0000\n",
            "Epoch 33400, Training loss 439394893824.0000, Validation loss 2130300370944.0000\n",
            "Epoch 33500, Training loss 436527464448.0000, Validation loss 2147801628672.0000\n",
            "Epoch 33600, Training loss 434070224896.0000, Validation loss 2159111307264.0000\n",
            "Epoch 33700, Training loss 431816605696.0000, Validation loss 2168679170048.0000\n",
            "Epoch 33800, Training loss 428826722304.0000, Validation loss 2179912564736.0000\n",
            "Epoch 33900, Training loss 426675077120.0000, Validation loss 2191315173376.0000\n",
            "Epoch 34000, Training loss 424685174784.0000, Validation loss 2205377101824.0000\n",
            "Epoch 34100, Training loss 422454853632.0000, Validation loss 2218167107584.0000\n",
            "Epoch 34200, Training loss 420238098432.0000, Validation loss 2227999080448.0000\n",
            "Epoch 34300, Training loss 418226208768.0000, Validation loss 2233325846528.0000\n",
            "Epoch 34400, Training loss 415528615936.0000, Validation loss 2237312794624.0000\n",
            "Epoch 34500, Training loss 413469343744.0000, Validation loss 2246763610112.0000\n",
            "Epoch 34600, Training loss 411547795456.0000, Validation loss 2259561218048.0000\n",
            "Epoch 34700, Training loss 409608716288.0000, Validation loss 2274457288704.0000\n",
            "Epoch 34800, Training loss 407519723520.0000, Validation loss 2287929917440.0000\n",
            "Epoch 34900, Training loss 405700804608.0000, Validation loss 2303224709120.0000\n",
            "Epoch 35000, Training loss 403672891392.0000, Validation loss 2320217407488.0000\n",
            "Epoch 35100, Training loss 401472651264.0000, Validation loss 2338762784768.0000\n",
            "Epoch 35200, Training loss 399322251264.0000, Validation loss 2355094355968.0000\n",
            "Epoch 35300, Training loss 397045760000.0000, Validation loss 2382621835264.0000\n",
            "Epoch 35400, Training loss 394536714240.0000, Validation loss 2405452480512.0000\n",
            "Epoch 35500, Training loss 392182202368.0000, Validation loss 2425335840768.0000\n",
            "Epoch 35600, Training loss 389677481984.0000, Validation loss 2450141478912.0000\n",
            "Epoch 35700, Training loss 387312812032.0000, Validation loss 2472197226496.0000\n",
            "Epoch 35800, Training loss 385188724736.0000, Validation loss 2492667789312.0000\n",
            "Epoch 35900, Training loss 382657101824.0000, Validation loss 2515333283840.0000\n",
            "Epoch 36000, Training loss 380164833280.0000, Validation loss 2532557193216.0000\n",
            "Epoch 36100, Training loss 377757335552.0000, Validation loss 2550204203008.0000\n",
            "Epoch 36200, Training loss 374552264704.0000, Validation loss 2562073034752.0000\n",
            "Epoch 36300, Training loss 371686670336.0000, Validation loss 2568438415360.0000\n",
            "Epoch 36400, Training loss 369361977344.0000, Validation loss 2583250337792.0000\n",
            "Epoch 36500, Training loss 367490367488.0000, Validation loss 2601291350016.0000\n",
            "Epoch 36600, Training loss 365806878720.0000, Validation loss 2620121415680.0000\n",
            "Epoch 36700, Training loss 364202917888.0000, Validation loss 2630072664064.0000\n",
            "Epoch 36800, Training loss 362434297856.0000, Validation loss 2641825366016.0000\n",
            "Epoch 36900, Training loss 360795504640.0000, Validation loss 2652097478656.0000\n",
            "Epoch 37000, Training loss 359160283136.0000, Validation loss 2662968066048.0000\n",
            "Epoch 37100, Training loss 357618712576.0000, Validation loss 2672426745856.0000\n",
            "Epoch 37200, Training loss 355993288704.0000, Validation loss 2686350524416.0000\n",
            "Epoch 37300, Training loss 354519580672.0000, Validation loss 2703699476480.0000\n",
            "Epoch 37400, Training loss 353186676736.0000, Validation loss 2720141410304.0000\n",
            "Epoch 37500, Training loss 351941984256.0000, Validation loss 2736427106304.0000\n",
            "Epoch 37600, Training loss 350617108480.0000, Validation loss 2727822229504.0000\n",
            "Epoch 37700, Training loss 349181739008.0000, Validation loss 2738321883136.0000\n",
            "Epoch 37800, Training loss 347552743424.0000, Validation loss 2749761585152.0000\n",
            "Epoch 37900, Training loss 345788186624.0000, Validation loss 2759496826880.0000\n",
            "Epoch 38000, Training loss 344062427136.0000, Validation loss 2769643896832.0000\n",
            "Epoch 38100, Training loss 342326149120.0000, Validation loss 2778356776960.0000\n",
            "Epoch 38200, Training loss 340187676672.0000, Validation loss 2781102473216.0000\n",
            "Epoch 38300, Training loss 338464800768.0000, Validation loss 2794124738560.0000\n",
            "Epoch 38400, Training loss 336973889536.0000, Validation loss 2809350062080.0000\n",
            "Epoch 38500, Training loss 335638167552.0000, Validation loss 2821806096384.0000\n",
            "Epoch 38600, Training loss 334364835840.0000, Validation loss 2833445814272.0000\n",
            "Epoch 38700, Training loss 332898631680.0000, Validation loss 2841002639360.0000\n",
            "Epoch 38800, Training loss 331014537216.0000, Validation loss 2833743085568.0000\n",
            "Epoch 38900, Training loss 329402155008.0000, Validation loss 2847872385024.0000\n",
            "Epoch 39000, Training loss 328049917952.0000, Validation loss 2862868332544.0000\n",
            "Epoch 39100, Training loss 326497009664.0000, Validation loss 2883889659904.0000\n",
            "Epoch 39200, Training loss 324550688768.0000, Validation loss 2911236784128.0000\n",
            "Epoch 39300, Training loss 323302522880.0000, Validation loss 2933456633856.0000\n",
            "Epoch 39400, Training loss 322099019776.0000, Validation loss 2955253121024.0000\n",
            "Epoch 39500, Training loss 320499515392.0000, Validation loss 2980512006144.0000\n",
            "Epoch 39600, Training loss 318927962112.0000, Validation loss 3010265350144.0000\n",
            "Epoch 39700, Training loss 316996354048.0000, Validation loss 3037098672128.0000\n",
            "Epoch 39800, Training loss 315358838784.0000, Validation loss 3058164826112.0000\n",
            "Epoch 39900, Training loss 313821396992.0000, Validation loss 3079581466624.0000\n",
            "Epoch 40000, Training loss 311763009536.0000, Validation loss 3109224972288.0000\n",
            "Epoch 40100, Training loss 310056714240.0000, Validation loss 3142115917824.0000\n",
            "Epoch 40200, Training loss 308351696896.0000, Validation loss 3171385081856.0000\n",
            "Epoch 40300, Training loss 306552668160.0000, Validation loss 3176630583296.0000\n",
            "Epoch 40400, Training loss 305191518208.0000, Validation loss 3193500598272.0000\n",
            "Epoch 40500, Training loss 303470116864.0000, Validation loss 3209020309504.0000\n",
            "Epoch 40600, Training loss 301661913088.0000, Validation loss 3216922378240.0000\n",
            "Epoch 40700, Training loss 299899518976.0000, Validation loss 3232174702592.0000\n",
            "Epoch 40800, Training loss 298246045696.0000, Validation loss 3247435415552.0000\n",
            "Epoch 40900, Training loss 296757362688.0000, Validation loss 3263459229696.0000\n",
            "Epoch 41000, Training loss 295240663040.0000, Validation loss 3289201246208.0000\n",
            "Epoch 41100, Training loss 293994856448.0000, Validation loss 3304066646016.0000\n",
            "Epoch 41200, Training loss 292934909952.0000, Validation loss 3319140974592.0000\n",
            "Epoch 41300, Training loss 291992895488.0000, Validation loss 3332498522112.0000\n",
            "Epoch 41400, Training loss 290857156608.0000, Validation loss 3353316950016.0000\n",
            "Epoch 41500, Training loss 289945223168.0000, Validation loss 3373395345408.0000\n",
            "Epoch 41600, Training loss 289153581056.0000, Validation loss 3392205225984.0000\n",
            "Epoch 41700, Training loss 288274644992.0000, Validation loss 3406254571520.0000\n",
            "Epoch 41800, Training loss 287405080576.0000, Validation loss 3423304417280.0000\n",
            "Epoch 41900, Training loss 286650761216.0000, Validation loss 3439638085632.0000\n",
            "Epoch 42000, Training loss 285985079296.0000, Validation loss 3455320588288.0000\n",
            "Epoch 42100, Training loss 285330604032.0000, Validation loss 3469433372672.0000\n",
            "Epoch 42200, Training loss 284642476032.0000, Validation loss 3483184922624.0000\n",
            "Epoch 42300, Training loss 283978432512.0000, Validation loss 3495890780160.0000\n",
            "Epoch 42400, Training loss 283351482368.0000, Validation loss 3512175951872.0000\n",
            "Epoch 42500, Training loss 282629570560.0000, Validation loss 3526948814848.0000\n",
            "Epoch 42600, Training loss 281925582848.0000, Validation loss 3541925625856.0000\n",
            "Epoch 42700, Training loss 281315639296.0000, Validation loss 3557322391552.0000\n",
            "Epoch 42800, Training loss 280764579840.0000, Validation loss 3573882552320.0000\n",
            "Epoch 42900, Training loss 280237965312.0000, Validation loss 3591565737984.0000\n",
            "Epoch 43000, Training loss 279746215936.0000, Validation loss 3607848550400.0000\n",
            "Epoch 43100, Training loss 279218454528.0000, Validation loss 3622486933504.0000\n",
            "Epoch 43200, Training loss 278299541504.0000, Validation loss 3635210878976.0000\n",
            "Epoch 43300, Training loss 277307850752.0000, Validation loss 3637583544320.0000\n",
            "Epoch 43400, Training loss 276621983744.0000, Validation loss 3643630944256.0000\n",
            "Epoch 43500, Training loss 276073218048.0000, Validation loss 3654450413568.0000\n",
            "Epoch 43600, Training loss 275423395840.0000, Validation loss 3679014354944.0000\n",
            "Epoch 43700, Training loss 274903302144.0000, Validation loss 3698537005056.0000\n",
            "Epoch 43800, Training loss 274442125312.0000, Validation loss 3716608425984.0000\n",
            "Epoch 43900, Training loss 273735614464.0000, Validation loss 3718554583040.0000\n",
            "Epoch 44000, Training loss 273111285760.0000, Validation loss 3713539244032.0000\n",
            "Epoch 44100, Training loss 272590684160.0000, Validation loss 3713359937536.0000\n",
            "Epoch 44200, Training loss 272118464512.0000, Validation loss 3713941110784.0000\n",
            "Epoch 44300, Training loss 271605841920.0000, Validation loss 3719435649024.0000\n",
            "Epoch 44400, Training loss 270796832768.0000, Validation loss 3711168937984.0000\n",
            "Epoch 44500, Training loss 270187134976.0000, Validation loss 3712197066752.0000\n",
            "Epoch 44600, Training loss 269700005888.0000, Validation loss 3717168103424.0000\n",
            "Epoch 44700, Training loss 269291012096.0000, Validation loss 3725275168768.0000\n",
            "Epoch 44800, Training loss 268921847808.0000, Validation loss 3731835584512.0000\n",
            "Epoch 44900, Training loss 268323864576.0000, Validation loss 3723249582080.0000\n",
            "Epoch 45000, Training loss 267661869056.0000, Validation loss 3723155996672.0000\n",
            "Epoch 45100, Training loss 267182325760.0000, Validation loss 3723439374336.0000\n",
            "Epoch 45200, Training loss 266784489472.0000, Validation loss 3725701152768.0000\n",
            "Epoch 45300, Training loss 266228580352.0000, Validation loss 3730393006080.0000\n",
            "Epoch 45400, Training loss 265629663232.0000, Validation loss 3733237268480.0000\n",
            "Epoch 45500, Training loss 265252175872.0000, Validation loss 3739856928768.0000\n",
            "Epoch 45600, Training loss 264806023168.0000, Validation loss 3750191431680.0000\n",
            "Epoch 45700, Training loss 264385069056.0000, Validation loss 3759136309248.0000\n",
            "Epoch 45800, Training loss 263857848320.0000, Validation loss 3765375598592.0000\n",
            "Epoch 45900, Training loss 263348109312.0000, Validation loss 3769584320512.0000\n",
            "Epoch 46000, Training loss 262855917568.0000, Validation loss 3774799413248.0000\n",
            "Epoch 46100, Training loss 262383648768.0000, Validation loss 3779569647616.0000\n",
            "Epoch 46200, Training loss 261997772800.0000, Validation loss 3786871406592.0000\n",
            "Epoch 46300, Training loss 261583994880.0000, Validation loss 3795118981120.0000\n",
            "Epoch 46400, Training loss 261263114240.0000, Validation loss 3803354497024.0000\n",
            "Epoch 46500, Training loss 260573986816.0000, Validation loss 3802613153792.0000\n",
            "Epoch 46600, Training loss 259696738304.0000, Validation loss 3796764721152.0000\n",
            "Epoch 46700, Training loss 258974875648.0000, Validation loss 3794822758400.0000\n",
            "Epoch 46800, Training loss 258330427392.0000, Validation loss 3789605306368.0000\n",
            "Epoch 46900, Training loss 257858387968.0000, Validation loss 3790867791872.0000\n",
            "Epoch 47000, Training loss 257412644864.0000, Validation loss 3792704634880.0000\n",
            "Epoch 47100, Training loss 257062027264.0000, Validation loss 3797955379200.0000\n",
            "Epoch 47200, Training loss 256770179072.0000, Validation loss 3803062468608.0000\n",
            "Epoch 47300, Training loss 256540147712.0000, Validation loss 3811413327872.0000\n",
            "Epoch 47400, Training loss 256315916288.0000, Validation loss 3818559111168.0000\n",
            "Epoch 47500, Training loss 256126353408.0000, Validation loss 3829275295744.0000\n",
            "Epoch 47600, Training loss 255950045184.0000, Validation loss 3837990797312.0000\n",
            "Epoch 47700, Training loss 255729352704.0000, Validation loss 3846219759616.0000\n",
            "Epoch 47800, Training loss 255536824320.0000, Validation loss 3855776481280.0000\n",
            "Epoch 47900, Training loss 255376556032.0000, Validation loss 3866186219520.0000\n",
            "Epoch 48000, Training loss 255213502464.0000, Validation loss 3876080582656.0000\n",
            "Epoch 48100, Training loss 254989484032.0000, Validation loss 3886255964160.0000\n",
            "Epoch 48200, Training loss 254743019520.0000, Validation loss 3893575548928.0000\n",
            "Epoch 48300, Training loss 254439211008.0000, Validation loss 3903109201920.0000\n",
            "Epoch 48400, Training loss 254206066688.0000, Validation loss 3915195088896.0000\n",
            "Epoch 48500, Training loss 253910384640.0000, Validation loss 3921516429312.0000\n",
            "Epoch 48600, Training loss 253677535232.0000, Validation loss 3928506499072.0000\n",
            "Epoch 48700, Training loss 253163569152.0000, Validation loss 3916993921024.0000\n",
            "Epoch 48800, Training loss 252595568640.0000, Validation loss 3911924056064.0000\n",
            "Epoch 48900, Training loss 252201402368.0000, Validation loss 3925672460288.0000\n",
            "Epoch 49000, Training loss 251882504192.0000, Validation loss 3941147869184.0000\n",
            "Epoch 49100, Training loss 251600486400.0000, Validation loss 3953001234432.0000\n",
            "Epoch 49200, Training loss 251262025728.0000, Validation loss 3957828878336.0000\n",
            "Epoch 49300, Training loss 250880606208.0000, Validation loss 3962915782656.0000\n",
            "Epoch 49400, Training loss 250524483584.0000, Validation loss 3967913295872.0000\n",
            "Epoch 49500, Training loss 250270236672.0000, Validation loss 3974160449536.0000\n",
            "Epoch 49600, Training loss 250058129408.0000, Validation loss 3979393368064.0000\n",
            "Epoch 49700, Training loss 249804865536.0000, Validation loss 3982697431040.0000\n",
            "Epoch 49800, Training loss 249598214144.0000, Validation loss 3986953076736.0000\n",
            "Epoch 49900, Training loss 249423413248.0000, Validation loss 3991334289408.0000\n",
            "Epoch 50000, Training loss 249119096832.0000, Validation loss 3994293633024.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1b: 2 hidden layers"
      ],
      "metadata": {
        "id": "dmLJHQGk3wTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = nn.Sequential(\n",
        "    nn.Linear(X1_train.shape[1], 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 1)\n",
        ")"
      ],
      "metadata": {
        "id": "j3JgTm8e257t"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer1 = optim.Adam(model1.parameters(), lr=1e-4)\n",
        "\n",
        "\n",
        "train_losses2, val_losses2 = training_loop(\n",
        "    n_epochs = 50000,\n",
        "    optimizer = optimizer1,  # Use the new optimizer\n",
        "    model = model1,\n",
        "    loss_fn = loss_fn,\n",
        "    X_train = X_train_tensor,\n",
        "    y_train = y_train_tensor,\n",
        "    X_val = X_val_tensor,\n",
        "    y_val = y_val_tensor\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or1GBwsP5Ai8",
        "outputId": "3f543929-ff92-4069-80df-aa8a07211ae4"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 26283924783104.0000, Validation loss 25017523896320.0000\n",
            "Epoch 100, Training loss 26275552952320.0000, Validation loss 25009793794048.0000\n",
            "Epoch 200, Training loss 26266675707904.0000, Validation loss 25001593929728.0000\n",
            "Epoch 300, Training loss 26257353867264.0000, Validation loss 24992983023616.0000\n",
            "Epoch 400, Training loss 26247572750336.0000, Validation loss 24983965270016.0000\n",
            "Epoch 500, Training loss 26237313482752.0000, Validation loss 24974498725888.0000\n",
            "Epoch 600, Training loss 26226557190144.0000, Validation loss 24964581294080.0000\n",
            "Epoch 700, Training loss 26215293386752.0000, Validation loss 24954194100224.0000\n",
            "Epoch 800, Training loss 26203505295360.0000, Validation loss 24943320367104.0000\n",
            "Epoch 900, Training loss 26191171944448.0000, Validation loss 24931945414656.0000\n",
            "Epoch 1000, Training loss 26178276556800.0000, Validation loss 24920052465664.0000\n",
            "Epoch 1100, Training loss 26164802355200.0000, Validation loss 24907635228672.0000\n",
            "Epoch 1200, Training loss 26150745145344.0000, Validation loss 24894676926464.0000\n",
            "Epoch 1300, Training loss 26136081858560.0000, Validation loss 24881160781824.0000\n",
            "Epoch 1400, Training loss 26120799911936.0000, Validation loss 24867074211840.0000\n",
            "Epoch 1500, Training loss 26104880431104.0000, Validation loss 24852404633600.0000\n",
            "Epoch 1600, Training loss 26088315027456.0000, Validation loss 24837137367040.0000\n",
            "Epoch 1700, Training loss 26071093215232.0000, Validation loss 24821261926400.0000\n",
            "Epoch 1800, Training loss 26053196120064.0000, Validation loss 24804763631616.0000\n",
            "Epoch 1900, Training loss 26034609061888.0000, Validation loss 24787640385536.0000\n",
            "Epoch 2000, Training loss 26015325749248.0000, Validation loss 24769873313792.0000\n",
            "Epoch 2100, Training loss 25995329404928.0000, Validation loss 24751456124928.0000\n",
            "Epoch 2200, Training loss 25974609543168.0000, Validation loss 24732376236032.0000\n",
            "Epoch 2300, Training loss 25953164066816.0000, Validation loss 24712616869888.0000\n",
            "Epoch 2400, Training loss 25930978295808.0000, Validation loss 24692171735040.0000\n",
            "Epoch 2500, Training loss 25908039647232.0000, Validation loss 24671028248576.0000\n",
            "Epoch 2600, Training loss 25884331343872.0000, Validation loss 24649188507648.0000\n",
            "Epoch 2700, Training loss 25859851288576.0000, Validation loss 24626637832192.0000\n",
            "Epoch 2800, Training loss 25834586898432.0000, Validation loss 24603372027904.0000\n",
            "Epoch 2900, Training loss 25808519299072.0000, Validation loss 24579382706176.0000\n",
            "Epoch 3000, Training loss 25781646393344.0000, Validation loss 24554661478400.0000\n",
            "Epoch 3100, Training loss 25753968181248.0000, Validation loss 24529162207232.0000\n",
            "Epoch 3200, Training loss 25725465788416.0000, Validation loss 24502897475584.0000\n",
            "Epoch 3300, Training loss 25696122437632.0000, Validation loss 24475854700544.0000\n",
            "Epoch 3400, Training loss 25665933934592.0000, Validation loss 24448038076416.0000\n",
            "Epoch 3500, Training loss 25634904473600.0000, Validation loss 24419435020288.0000\n",
            "Epoch 3600, Training loss 25602994208768.0000, Validation loss 24390037143552.0000\n",
            "Epoch 3700, Training loss 25570213625856.0000, Validation loss 24359825571840.0000\n",
            "Epoch 3800, Training loss 25536541753344.0000, Validation loss 24328783527936.0000\n",
            "Epoch 3900, Training loss 25501974396928.0000, Validation loss 24296911011840.0000\n",
            "Epoch 4000, Training loss 25466498973696.0000, Validation loss 24264205926400.0000\n",
            "Epoch 4100, Training loss 25430100803584.0000, Validation loss 24230649397248.0000\n",
            "Epoch 4200, Training loss 25392788275200.0000, Validation loss 24196245618688.0000\n",
            "Epoch 4300, Training loss 25354544611328.0000, Validation loss 24160988299264.0000\n",
            "Epoch 4400, Training loss 25315365617664.0000, Validation loss 24124873244672.0000\n",
            "Epoch 4500, Training loss 25275234516992.0000, Validation loss 24087885774848.0000\n",
            "Epoch 4600, Training loss 25234145017856.0000, Validation loss 24050007015424.0000\n",
            "Epoch 4700, Training loss 25192090828800.0000, Validation loss 24011239063552.0000\n",
            "Epoch 4800, Training loss 25149067755520.0000, Validation loss 23971571433472.0000\n",
            "Epoch 4900, Training loss 25105059020800.0000, Validation loss 23930997833728.0000\n",
            "Epoch 5000, Training loss 25060058333184.0000, Validation loss 23889495195648.0000\n",
            "Epoch 5100, Training loss 25014053109760.0000, Validation loss 23847067713536.0000\n",
            "Epoch 5200, Training loss 24967037059072.0000, Validation loss 23803702804480.0000\n",
            "Epoch 5300, Training loss 24918999695360.0000, Validation loss 23759400468480.0000\n",
            "Epoch 5400, Training loss 24869936824320.0000, Validation loss 23714150219776.0000\n",
            "Epoch 5500, Training loss 24819827474432.0000, Validation loss 23667945766912.0000\n",
            "Epoch 5600, Training loss 24768671645696.0000, Validation loss 23620778721280.0000\n",
            "Epoch 5700, Training loss 24716467240960.0000, Validation loss 23572640694272.0000\n",
            "Epoch 5800, Training loss 24663201677312.0000, Validation loss 23523523297280.0000\n",
            "Epoch 5900, Training loss 24608864468992.0000, Validation loss 23473420238848.0000\n",
            "Epoch 6000, Training loss 24553451421696.0000, Validation loss 23422318936064.0000\n",
            "Epoch 6100, Training loss 24496947855360.0000, Validation loss 23370198417408.0000\n",
            "Epoch 6200, Training loss 24439343284224.0000, Validation loss 23317054488576.0000\n",
            "Epoch 6300, Training loss 24380631416832.0000, Validation loss 23262897635328.0000\n",
            "Epoch 6400, Training loss 24320812253184.0000, Validation loss 23207719469056.0000\n",
            "Epoch 6500, Training loss 24259871113216.0000, Validation loss 23151509504000.0000\n",
            "Epoch 6600, Training loss 24197799608320.0000, Validation loss 23094234185728.0000\n",
            "Epoch 6700, Training loss 24134589349888.0000, Validation loss 23035912388608.0000\n",
            "Epoch 6800, Training loss 24070240337920.0000, Validation loss 22976537821184.0000\n",
            "Epoch 6900, Training loss 24004744183808.0000, Validation loss 22916108386304.0000\n",
            "Epoch 7000, Training loss 23938098790400.0000, Validation loss 22854598918144.0000\n",
            "Epoch 7100, Training loss 23870295769088.0000, Validation loss 22792021999616.0000\n",
            "Epoch 7200, Training loss 23801328828416.0000, Validation loss 22728369242112.0000\n",
            "Epoch 7300, Training loss 23731193774080.0000, Validation loss 22663636451328.0000\n",
            "Epoch 7400, Training loss 23659882217472.0000, Validation loss 22597813141504.0000\n",
            "Epoch 7500, Training loss 23587385769984.0000, Validation loss 22530909798400.0000\n",
            "Epoch 7600, Training loss 23513702334464.0000, Validation loss 22462913839104.0000\n",
            "Epoch 7700, Training loss 23438819328000.0000, Validation loss 22393804292096.0000\n",
            "Epoch 7800, Training loss 23362730459136.0000, Validation loss 22323572768768.0000\n",
            "Epoch 7900, Training loss 23285446213632.0000, Validation loss 22252225560576.0000\n",
            "Epoch 8000, Training loss 23206939328512.0000, Validation loss 22179789930496.0000\n",
            "Epoch 8100, Training loss 23127213998080.0000, Validation loss 22106251198464.0000\n",
            "Epoch 8200, Training loss 23046268125184.0000, Validation loss 22031596781568.0000\n",
            "Epoch 8300, Training loss 22964093321216.0000, Validation loss 21955818291200.0000\n",
            "Epoch 8400, Training loss 22880697974784.0000, Validation loss 21878913630208.0000\n",
            "Epoch 8500, Training loss 22796050628608.0000, Validation loss 21800899575808.0000\n",
            "Epoch 8600, Training loss 22710159671296.0000, Validation loss 21721736282112.0000\n",
            "Epoch 8700, Training loss 22623037685760.0000, Validation loss 21641411166208.0000\n",
            "Epoch 8800, Training loss 22534695157760.0000, Validation loss 21559932616704.0000\n",
            "Epoch 8900, Training loss 22445102727168.0000, Validation loss 21477311119360.0000\n",
            "Epoch 9000, Training loss 22354247811072.0000, Validation loss 21393487953920.0000\n",
            "Epoch 9100, Training loss 22262147186688.0000, Validation loss 21308488286208.0000\n",
            "Epoch 9200, Training loss 22168788271104.0000, Validation loss 21222335184896.0000\n",
            "Epoch 9300, Training loss 22074162675712.0000, Validation loss 21135028649984.0000\n",
            "Epoch 9400, Training loss 21978274594816.0000, Validation loss 21046566584320.0000\n",
            "Epoch 9500, Training loss 21881132417024.0000, Validation loss 20956965765120.0000\n",
            "Epoch 9600, Training loss 21782755016704.0000, Validation loss 20866211512320.0000\n",
            "Epoch 9700, Training loss 21683150782464.0000, Validation loss 20774314311680.0000\n",
            "Epoch 9800, Training loss 21582309228544.0000, Validation loss 20681269968896.0000\n",
            "Epoch 9900, Training loss 21480232452096.0000, Validation loss 20587070095360.0000\n",
            "Epoch 10000, Training loss 21376937230336.0000, Validation loss 20491727273984.0000\n",
            "Epoch 10100, Training loss 21272421466112.0000, Validation loss 20395258281984.0000\n",
            "Epoch 10200, Training loss 21166687256576.0000, Validation loss 20297661022208.0000\n",
            "Epoch 10300, Training loss 21059740893184.0000, Validation loss 20198945980416.0000\n",
            "Epoch 10400, Training loss 20951569793024.0000, Validation loss 20099102670848.0000\n",
            "Epoch 10500, Training loss 20842194927616.0000, Validation loss 19998139482112.0000\n",
            "Epoch 10600, Training loss 20731620491264.0000, Validation loss 19896050122752.0000\n",
            "Epoch 10700, Training loss 20619852775424.0000, Validation loss 19792853467136.0000\n",
            "Epoch 10800, Training loss 20506885488640.0000, Validation loss 19688549515264.0000\n",
            "Epoch 10900, Training loss 20392739602432.0000, Validation loss 19583146655744.0000\n",
            "Epoch 11000, Training loss 20277415116800.0000, Validation loss 19476651180032.0000\n",
            "Epoch 11100, Training loss 20160916226048.0000, Validation loss 19369071476736.0000\n",
            "Epoch 11200, Training loss 20043247124480.0000, Validation loss 19260409643008.0000\n",
            "Epoch 11300, Training loss 19924426686464.0000, Validation loss 19150682456064.0000\n",
            "Epoch 11400, Training loss 19804471689216.0000, Validation loss 19039896207360.0000\n",
            "Epoch 11500, Training loss 19683380035584.0000, Validation loss 18928061382656.0000\n",
            "Epoch 11600, Training loss 19561162211328.0000, Validation loss 18815186370560.0000\n",
            "Epoch 11700, Training loss 19437830799360.0000, Validation loss 18701279559680.0000\n",
            "Epoch 11800, Training loss 19313402576896.0000, Validation loss 18586349338624.0000\n",
            "Epoch 11900, Training loss 19187888029696.0000, Validation loss 18470412484608.0000\n",
            "Epoch 12000, Training loss 19061303934976.0000, Validation loss 18353473191936.0000\n",
            "Epoch 12100, Training loss 18933646098432.0000, Validation loss 18235533557760.0000\n",
            "Epoch 12200, Training loss 18804925005824.0000, Validation loss 18116608262144.0000\n",
            "Epoch 12300, Training loss 18675123879936.0000, Validation loss 17996693110784.0000\n",
            "Epoch 12400, Training loss 18544265789440.0000, Validation loss 17875786006528.0000\n",
            "Epoch 12500, Training loss 18412403163136.0000, Validation loss 17753958252544.0000\n",
            "Epoch 12600, Training loss 18279546486784.0000, Validation loss 17631209848832.0000\n",
            "Epoch 12700, Training loss 18145708343296.0000, Validation loss 17507539746816.0000\n",
            "Epoch 12800, Training loss 18010920189952.0000, Validation loss 17382991986688.0000\n",
            "Epoch 12900, Training loss 17875200901120.0000, Validation loss 17257576005632.0000\n",
            "Epoch 13000, Training loss 17738579836928.0000, Validation loss 17131308580864.0000\n",
            "Epoch 13100, Training loss 17601088454656.0000, Validation loss 17004208586752.0000\n",
            "Epoch 13200, Training loss 17462718365696.0000, Validation loss 16876292800512.0000\n",
            "Epoch 13300, Training loss 17323502075904.0000, Validation loss 16747580096512.0000\n",
            "Epoch 13400, Training loss 17183455313920.0000, Validation loss 16618094592000.0000\n",
            "Epoch 13500, Training loss 17042604294144.0000, Validation loss 16487844675584.0000\n",
            "Epoch 13600, Training loss 16900969988096.0000, Validation loss 16356862853120.0000\n",
            "Epoch 13700, Training loss 16758592241664.0000, Validation loss 16225180581888.0000\n",
            "Epoch 13800, Training loss 16615474200576.0000, Validation loss 16092804153344.0000\n",
            "Epoch 13900, Training loss 16471646273536.0000, Validation loss 15959751393280.0000\n",
            "Epoch 14000, Training loss 16327159840768.0000, Validation loss 15826049564672.0000\n",
            "Epoch 14100, Training loss 16182031679488.0000, Validation loss 15691731173376.0000\n",
            "Epoch 14200, Training loss 16036279615488.0000, Validation loss 15556818239488.0000\n",
            "Epoch 14300, Training loss 15889933008896.0000, Validation loss 15421339074560.0000\n",
            "Epoch 14400, Training loss 15743013879808.0000, Validation loss 15285315698688.0000\n",
            "Epoch 14500, Training loss 15595563122688.0000, Validation loss 15148781666304.0000\n",
            "Epoch 14600, Training loss 15447610097664.0000, Validation loss 15011763191808.0000\n",
            "Epoch 14700, Training loss 15299187310592.0000, Validation loss 14874296975360.0000\n",
            "Epoch 14800, Training loss 15150336704512.0000, Validation loss 14736415522816.0000\n",
            "Epoch 14900, Training loss 15001085542400.0000, Validation loss 14598140854272.0000\n",
            "Epoch 15000, Training loss 14851466330112.0000, Validation loss 14459501281280.0000\n",
            "Epoch 15100, Training loss 14701511573504.0000, Validation loss 14320538746880.0000\n",
            "Epoch 15200, Training loss 14551265312768.0000, Validation loss 14181283659776.0000\n",
            "Epoch 15300, Training loss 14400761102336.0000, Validation loss 14041764331520.0000\n",
            "Epoch 15400, Training loss 14250022010880.0000, Validation loss 13901998587904.0000\n",
            "Epoch 15500, Training loss 14099097321472.0000, Validation loss 13762035712000.0000\n",
            "Epoch 15600, Training loss 13948024782848.0000, Validation loss 13621907161088.0000\n",
            "Epoch 15700, Training loss 13796847386624.0000, Validation loss 13481646489600.0000\n",
            "Epoch 15800, Training loss 13645608124416.0000, Validation loss 13341296689152.0000\n",
            "Epoch 15900, Training loss 13494348939264.0000, Validation loss 13200890265600.0000\n",
            "Epoch 16000, Training loss 13343107579904.0000, Validation loss 13060466016256.0000\n",
            "Epoch 16100, Training loss 13191929135104.0000, Validation loss 12920064835584.0000\n",
            "Epoch 16200, Training loss 13040855547904.0000, Validation loss 12779724472320.0000\n",
            "Epoch 16300, Training loss 12889939247104.0000, Validation loss 12639494209536.0000\n",
            "Epoch 16400, Training loss 12739216932864.0000, Validation loss 12499408650240.0000\n",
            "Epoch 16500, Training loss 12588732645376.0000, Validation loss 12359509737472.0000\n",
            "Epoch 16600, Training loss 12438524133376.0000, Validation loss 12219839414272.0000\n",
            "Epoch 16700, Training loss 12288636485632.0000, Validation loss 12080436477952.0000\n",
            "Epoch 16800, Training loss 12139129470976.0000, Validation loss 11941350211584.0000\n",
            "Epoch 16900, Training loss 11990057615360.0000, Validation loss 11802622558208.0000\n",
            "Epoch 17000, Training loss 11841466007552.0000, Validation loss 11664299655168.0000\n",
            "Epoch 17100, Training loss 11693396590592.0000, Validation loss 11526422396928.0000\n",
            "Epoch 17200, Training loss 11545911230464.0000, Validation loss 11389037969408.0000\n",
            "Epoch 17300, Training loss 11399052918784.0000, Validation loss 11252187267072.0000\n",
            "Epoch 17400, Training loss 11252883521536.0000, Validation loss 11115925864448.0000\n",
            "Epoch 17500, Training loss 11107454418944.0000, Validation loss 10980295704576.0000\n",
            "Epoch 17600, Training loss 10962812796928.0000, Validation loss 10845345021952.0000\n",
            "Epoch 17700, Training loss 10819011084288.0000, Validation loss 10711116808192.0000\n",
            "Epoch 17800, Training loss 10676103806976.0000, Validation loss 10577659297792.0000\n",
            "Epoch 17900, Training loss 10534143393792.0000, Validation loss 10445031211008.0000\n",
            "Epoch 18000, Training loss 10393183322112.0000, Validation loss 10313280782336.0000\n",
            "Epoch 18100, Training loss 10253262389248.0000, Validation loss 10182448906240.0000\n",
            "Epoch 18200, Training loss 10114435121152.0000, Validation loss 10052590108672.0000\n",
            "Epoch 18300, Training loss 9976779112448.0000, Validation loss 9923756818432.0000\n",
            "Epoch 18400, Training loss 9840335257600.0000, Validation loss 9795992027136.0000\n",
            "Epoch 18500, Training loss 9705154936832.0000, Validation loss 9669337677824.0000\n",
            "Epoch 18600, Training loss 9571302113280.0000, Validation loss 9543854587904.0000\n",
            "Epoch 18700, Training loss 9438822924288.0000, Validation loss 9419583651840.0000\n",
            "Epoch 18800, Training loss 9307766652928.0000, Validation loss 9296574152704.0000\n",
            "Epoch 18900, Training loss 9178187825152.0000, Validation loss 9174878519296.0000\n",
            "Epoch 19000, Training loss 9050139918336.0000, Validation loss 9054535548928.0000\n",
            "Epoch 19100, Training loss 8923662778368.0000, Validation loss 8935592427520.0000\n",
            "Epoch 19200, Training loss 8798808834048.0000, Validation loss 8818102632448.0000\n",
            "Epoch 19300, Training loss 8675626844160.0000, Validation loss 8702090805248.0000\n",
            "Epoch 19400, Training loss 8554173956096.0000, Validation loss 8587613569024.0000\n",
            "Epoch 19500, Training loss 8434490540032.0000, Validation loss 8474709196800.0000\n",
            "Epoch 19600, Training loss 8316622733312.0000, Validation loss 8363417534464.0000\n",
            "Epoch 19700, Training loss 8200608284672.0000, Validation loss 8253776330752.0000\n",
            "Epoch 19800, Training loss 8086488612864.0000, Validation loss 8145820188672.0000\n",
            "Epoch 19900, Training loss 7974304088064.0000, Validation loss 8039585284096.0000\n",
            "Epoch 20000, Training loss 7864084594688.0000, Validation loss 7935089442816.0000\n",
            "Epoch 20100, Training loss 7755862114304.0000, Validation loss 7832371986432.0000\n",
            "Epoch 20200, Training loss 7649664958464.0000, Validation loss 7731464896512.0000\n",
            "Epoch 20300, Training loss 7545512525824.0000, Validation loss 7632392290304.0000\n",
            "Epoch 20400, Training loss 7443427885056.0000, Validation loss 7535178809344.0000\n",
            "Epoch 20500, Training loss 7343424143360.0000, Validation loss 7439837560832.0000\n",
            "Epoch 20600, Training loss 7245524369408.0000, Validation loss 7346406293504.0000\n",
            "Epoch 20700, Training loss 7149731184640.0000, Validation loss 7254892871680.0000\n",
            "Epoch 20800, Training loss 7056070279168.0000, Validation loss 7165291003904.0000\n",
            "Epoch 20900, Training loss 6964544798720.0000, Validation loss 7077608554496.0000\n",
            "Epoch 21000, Training loss 6875156840448.0000, Validation loss 6991887466496.0000\n",
            "Epoch 21100, Training loss 6787896442880.0000, Validation loss 6908122497024.0000\n",
            "Epoch 21200, Training loss 6702774091776.0000, Validation loss 6826330947584.0000\n",
            "Epoch 21300, Training loss 6619751514112.0000, Validation loss 6746493943808.0000\n",
            "Epoch 21400, Training loss 6538826612736.0000, Validation loss 6668600475648.0000\n",
            "Epoch 21500, Training loss 6459977891840.0000, Validation loss 6592657883136.0000\n",
            "Epoch 21600, Training loss 6383220031488.0000, Validation loss 6518661971968.0000\n",
            "Epoch 21700, Training loss 6308494311424.0000, Validation loss 6446523613184.0000\n",
            "Epoch 21800, Training loss 6235796537344.0000, Validation loss 6376274264064.0000\n",
            "Epoch 21900, Training loss 6165101019136.0000, Validation loss 6307879845888.0000\n",
            "Epoch 22000, Training loss 6096370532352.0000, Validation loss 6241311522816.0000\n",
            "Epoch 22100, Training loss 6029562085376.0000, Validation loss 6176520536064.0000\n",
            "Epoch 22200, Training loss 5964662046720.0000, Validation loss 6113507409920.0000\n",
            "Epoch 22300, Training loss 5901600161792.0000, Validation loss 6052226531328.0000\n",
            "Epoch 22400, Training loss 5840328720384.0000, Validation loss 5992619180032.0000\n",
            "Epoch 22500, Training loss 5780788477952.0000, Validation loss 5934628732928.0000\n",
            "Epoch 22600, Training loss 5722931724288.0000, Validation loss 5878224781312.0000\n",
            "Epoch 22700, Training loss 5666671427584.0000, Validation loss 5823297748992.0000\n",
            "Epoch 22800, Training loss 5611946246144.0000, Validation loss 5769761652736.0000\n",
            "Epoch 22900, Training loss 5558653419520.0000, Validation loss 5717579268096.0000\n",
            "Epoch 23000, Training loss 5506701721600.0000, Validation loss 5666616377344.0000\n",
            "Epoch 23100, Training loss 5456028762112.0000, Validation loss 5616874029056.0000\n",
            "Epoch 23200, Training loss 5406527062016.0000, Validation loss 5568216956928.0000\n",
            "Epoch 23300, Training loss 5358140522496.0000, Validation loss 5520597450752.0000\n",
            "Epoch 23400, Training loss 5310763237376.0000, Validation loss 5473900691456.0000\n",
            "Epoch 23500, Training loss 5264332292096.0000, Validation loss 5428043841536.0000\n",
            "Epoch 23600, Training loss 5218745450496.0000, Validation loss 5382968705024.0000\n",
            "Epoch 23700, Training loss 5173944516608.0000, Validation loss 5338612367360.0000\n",
            "Epoch 23800, Training loss 5129838264320.0000, Validation loss 5294816493568.0000\n",
            "Epoch 23900, Training loss 5086326030336.0000, Validation loss 5251483566080.0000\n",
            "Epoch 24000, Training loss 5043362725888.0000, Validation loss 5208550670336.0000\n",
            "Epoch 24100, Training loss 5000854503424.0000, Validation loss 5165949124608.0000\n",
            "Epoch 24200, Training loss 4958734778368.0000, Validation loss 5123632267264.0000\n",
            "Epoch 24300, Training loss 4916955316224.0000, Validation loss 5081494716416.0000\n",
            "Epoch 24400, Training loss 4875445338112.0000, Validation loss 5039477227520.0000\n",
            "Epoch 24500, Training loss 4834171813888.0000, Validation loss 4997567217664.0000\n",
            "Epoch 24600, Training loss 4793105383424.0000, Validation loss 4955705966592.0000\n",
            "Epoch 24700, Training loss 4752193093632.0000, Validation loss 4913890852864.0000\n",
            "Epoch 24800, Training loss 4711352631296.0000, Validation loss 4872047427584.0000\n",
            "Epoch 24900, Training loss 4670504304640.0000, Validation loss 4830110679040.0000\n",
            "Epoch 25000, Training loss 4629638152192.0000, Validation loss 4788059111424.0000\n",
            "Epoch 25100, Training loss 4588782485504.0000, Validation loss 4745980805120.0000\n",
            "Epoch 25200, Training loss 4547964043264.0000, Validation loss 4703847448576.0000\n",
            "Epoch 25300, Training loss 4507162902528.0000, Validation loss 4661636497408.0000\n",
            "Epoch 25400, Training loss 4466365431808.0000, Validation loss 4619466440704.0000\n",
            "Epoch 25500, Training loss 4425568485376.0000, Validation loss 4577217216512.0000\n",
            "Epoch 25600, Training loss 4384742440960.0000, Validation loss 4534942302208.0000\n",
            "Epoch 25700, Training loss 4343865278464.0000, Validation loss 4492627542016.0000\n",
            "Epoch 25800, Training loss 4302937784320.0000, Validation loss 4450249342976.0000\n",
            "Epoch 25900, Training loss 4261977260032.0000, Validation loss 4407849123840.0000\n",
            "Epoch 26000, Training loss 4221025124352.0000, Validation loss 4365390970880.0000\n",
            "Epoch 26100, Training loss 4180096319488.0000, Validation loss 4322835300352.0000\n",
            "Epoch 26200, Training loss 4139201593344.0000, Validation loss 4280253153280.0000\n",
            "Epoch 26300, Training loss 4098322333696.0000, Validation loss 4237628276736.0000\n",
            "Epoch 26400, Training loss 4057497600000.0000, Validation loss 4195030925312.0000\n",
            "Epoch 26500, Training loss 4016668409856.0000, Validation loss 4152521392128.0000\n",
            "Epoch 26600, Training loss 3975898726400.0000, Validation loss 4110036762624.0000\n",
            "Epoch 26700, Training loss 3935215026176.0000, Validation loss 4067516219392.0000\n",
            "Epoch 26800, Training loss 3894663446528.0000, Validation loss 4024942198784.0000\n",
            "Epoch 26900, Training loss 3854203617280.0000, Validation loss 3982424014848.0000\n",
            "Epoch 27000, Training loss 3813821382656.0000, Validation loss 3939943579648.0000\n",
            "Epoch 27100, Training loss 3773613998080.0000, Validation loss 3897554632704.0000\n",
            "Epoch 27200, Training loss 3733584347136.0000, Validation loss 3855204483072.0000\n",
            "Epoch 27300, Training loss 3693682360320.0000, Validation loss 3812940054528.0000\n",
            "Epoch 27400, Training loss 3653968330752.0000, Validation loss 3770778910720.0000\n",
            "Epoch 27500, Training loss 3614483152896.0000, Validation loss 3728693526528.0000\n",
            "Epoch 27600, Training loss 3575223418880.0000, Validation loss 3686705659904.0000\n",
            "Epoch 27700, Training loss 3536269869056.0000, Validation loss 3644893691904.0000\n",
            "Epoch 27800, Training loss 3497671786496.0000, Validation loss 3603333382144.0000\n",
            "Epoch 27900, Training loss 3459459055616.0000, Validation loss 3561985933312.0000\n",
            "Epoch 28000, Training loss 3421671522304.0000, Validation loss 3520893550592.0000\n",
            "Epoch 28100, Training loss 3384222679040.0000, Validation loss 3480036573184.0000\n",
            "Epoch 28200, Training loss 3347123011584.0000, Validation loss 3439330590720.0000\n",
            "Epoch 28300, Training loss 3310420492288.0000, Validation loss 3398876266496.0000\n",
            "Epoch 28400, Training loss 3274094411776.0000, Validation loss 3358772428800.0000\n",
            "Epoch 28500, Training loss 3238152110080.0000, Validation loss 3318975561728.0000\n",
            "Epoch 28600, Training loss 3202626093056.0000, Validation loss 3279496937472.0000\n",
            "Epoch 28700, Training loss 3167524225024.0000, Validation loss 3240358838272.0000\n",
            "Epoch 28800, Training loss 3132873768960.0000, Validation loss 3201548681216.0000\n",
            "Epoch 28900, Training loss 3098663190528.0000, Validation loss 3162986774528.0000\n",
            "Epoch 29000, Training loss 3064863653888.0000, Validation loss 3124718993408.0000\n",
            "Epoch 29100, Training loss 3031554326528.0000, Validation loss 3086854389760.0000\n",
            "Epoch 29200, Training loss 2998688808960.0000, Validation loss 3049344466944.0000\n",
            "Epoch 29300, Training loss 2966345744384.0000, Validation loss 3012263936000.0000\n",
            "Epoch 29400, Training loss 2934569697280.0000, Validation loss 2975644778496.0000\n",
            "Epoch 29500, Training loss 2903403921408.0000, Validation loss 2939528937472.0000\n",
            "Epoch 29600, Training loss 2872793104384.0000, Validation loss 2903893868544.0000\n",
            "Epoch 29700, Training loss 2842787315712.0000, Validation loss 2868822409216.0000\n",
            "Epoch 29800, Training loss 2813398089728.0000, Validation loss 2834360172544.0000\n",
            "Epoch 29900, Training loss 2784555171840.0000, Validation loss 2800296394752.0000\n",
            "Epoch 30000, Training loss 2756231036928.0000, Validation loss 2766635532288.0000\n",
            "Epoch 30100, Training loss 2728464220160.0000, Validation loss 2733445742592.0000\n",
            "Epoch 30200, Training loss 2701275168768.0000, Validation loss 2700925468672.0000\n",
            "Epoch 30300, Training loss 2674687737856.0000, Validation loss 2669014679552.0000\n",
            "Epoch 30400, Training loss 2648641896448.0000, Validation loss 2637542457344.0000\n",
            "Epoch 30500, Training loss 2623162548224.0000, Validation loss 2606686011392.0000\n",
            "Epoch 30600, Training loss 2598267518976.0000, Validation loss 2576403660800.0000\n",
            "Epoch 30700, Training loss 2573922205696.0000, Validation loss 2546701172736.0000\n",
            "Epoch 30800, Training loss 2550107209728.0000, Validation loss 2517582217216.0000\n",
            "Epoch 30900, Training loss 2526885183488.0000, Validation loss 2489050202112.0000\n",
            "Epoch 31000, Training loss 2504243544064.0000, Validation loss 2461039591424.0000\n",
            "Epoch 31100, Training loss 2482093948928.0000, Validation loss 2433548812288.0000\n",
            "Epoch 31200, Training loss 2460417523712.0000, Validation loss 2406589136896.0000\n",
            "Epoch 31300, Training loss 2439202996224.0000, Validation loss 2380127010816.0000\n",
            "Epoch 31400, Training loss 2418454560768.0000, Validation loss 2354248941568.0000\n",
            "Epoch 31500, Training loss 2398144692224.0000, Validation loss 2328874188800.0000\n",
            "Epoch 31600, Training loss 2378290429952.0000, Validation loss 2303962906624.0000\n",
            "Epoch 31700, Training loss 2358836985856.0000, Validation loss 2279407353856.0000\n",
            "Epoch 31800, Training loss 2339781214208.0000, Validation loss 2255356428288.0000\n",
            "Epoch 31900, Training loss 2321192321024.0000, Validation loss 2231873306624.0000\n",
            "Epoch 32000, Training loss 2303083937792.0000, Validation loss 2209017495552.0000\n",
            "Epoch 32100, Training loss 2285435879424.0000, Validation loss 2186705108992.0000\n",
            "Epoch 32200, Training loss 2268196503552.0000, Validation loss 2165004959744.0000\n",
            "Epoch 32300, Training loss 2251356635136.0000, Validation loss 2143794495488.0000\n",
            "Epoch 32400, Training loss 2234862272512.0000, Validation loss 2123080794112.0000\n",
            "Epoch 32500, Training loss 2218679861248.0000, Validation loss 2102835281920.0000\n",
            "Epoch 32600, Training loss 2202781876224.0000, Validation loss 2082972631040.0000\n",
            "Epoch 32700, Training loss 2187180376064.0000, Validation loss 2063462170624.0000\n",
            "Epoch 32800, Training loss 2171853996032.0000, Validation loss 2044401811456.0000\n",
            "Epoch 32900, Training loss 2156795133952.0000, Validation loss 2025719988224.0000\n",
            "Epoch 33000, Training loss 2141974429696.0000, Validation loss 2007341465600.0000\n",
            "Epoch 33100, Training loss 2127444574208.0000, Validation loss 1989312249856.0000\n",
            "Epoch 33200, Training loss 2113162969088.0000, Validation loss 1971751092224.0000\n",
            "Epoch 33300, Training loss 2099137216512.0000, Validation loss 1954679750656.0000\n",
            "Epoch 33400, Training loss 2085313183744.0000, Validation loss 1938039898112.0000\n",
            "Epoch 33500, Training loss 2071716036608.0000, Validation loss 1921822097408.0000\n",
            "Epoch 33600, Training loss 2058303307776.0000, Validation loss 1905960026112.0000\n",
            "Epoch 33700, Training loss 2045078929408.0000, Validation loss 1890427731968.0000\n",
            "Epoch 33800, Training loss 2032031760384.0000, Validation loss 1875233734656.0000\n",
            "Epoch 33900, Training loss 2019156688896.0000, Validation loss 1860370563072.0000\n",
            "Epoch 34000, Training loss 2006436544512.0000, Validation loss 1845847654400.0000\n",
            "Epoch 34100, Training loss 1993833709568.0000, Validation loss 1831666057216.0000\n",
            "Epoch 34200, Training loss 1981380427776.0000, Validation loss 1817924337664.0000\n",
            "Epoch 34300, Training loss 1969083383808.0000, Validation loss 1804476350464.0000\n",
            "Epoch 34400, Training loss 1956980064256.0000, Validation loss 1791327731712.0000\n",
            "Epoch 34500, Training loss 1945035341824.0000, Validation loss 1778459869184.0000\n",
            "Epoch 34600, Training loss 1933146587136.0000, Validation loss 1765848252416.0000\n",
            "Epoch 34700, Training loss 1921399390208.0000, Validation loss 1753442156544.0000\n",
            "Epoch 34800, Training loss 1909786935296.0000, Validation loss 1741316030464.0000\n",
            "Epoch 34900, Training loss 1898274095104.0000, Validation loss 1729400799232.0000\n",
            "Epoch 35000, Training loss 1886902943744.0000, Validation loss 1717742338048.0000\n",
            "Epoch 35100, Training loss 1875638091776.0000, Validation loss 1706293460992.0000\n",
            "Epoch 35200, Training loss 1864479539200.0000, Validation loss 1694989942784.0000\n",
            "Epoch 35300, Training loss 1853444325376.0000, Validation loss 1683938738176.0000\n",
            "Epoch 35400, Training loss 1842505449472.0000, Validation loss 1673087680512.0000\n",
            "Epoch 35500, Training loss 1831626866688.0000, Validation loss 1662315397120.0000\n",
            "Epoch 35600, Training loss 1820865986560.0000, Validation loss 1651645480960.0000\n",
            "Epoch 35700, Training loss 1810240503808.0000, Validation loss 1641141370880.0000\n",
            "Epoch 35800, Training loss 1799750418432.0000, Validation loss 1630806605824.0000\n",
            "Epoch 35900, Training loss 1789374103552.0000, Validation loss 1620636336128.0000\n",
            "Epoch 36000, Training loss 1779078397952.0000, Validation loss 1610625843200.0000\n",
            "Epoch 36100, Training loss 1768878505984.0000, Validation loss 1600833585152.0000\n",
            "Epoch 36200, Training loss 1758731436032.0000, Validation loss 1591284334592.0000\n",
            "Epoch 36300, Training loss 1748680572928.0000, Validation loss 1581877690368.0000\n",
            "Epoch 36400, Training loss 1738699571200.0000, Validation loss 1572511154176.0000\n",
            "Epoch 36500, Training loss 1728808878080.0000, Validation loss 1563345944576.0000\n",
            "Epoch 36600, Training loss 1718988177408.0000, Validation loss 1554307481600.0000\n",
            "Epoch 36700, Training loss 1709239042048.0000, Validation loss 1545335341056.0000\n",
            "Epoch 36800, Training loss 1699581657088.0000, Validation loss 1536573833216.0000\n",
            "Epoch 36900, Training loss 1690034372608.0000, Validation loss 1527951261696.0000\n",
            "Epoch 37000, Training loss 1680626941952.0000, Validation loss 1519494496256.0000\n",
            "Epoch 37100, Training loss 1671284129792.0000, Validation loss 1511161593856.0000\n",
            "Epoch 37200, Training loss 1662034771968.0000, Validation loss 1502936301568.0000\n",
            "Epoch 37300, Training loss 1652894728192.0000, Validation loss 1494729097216.0000\n",
            "Epoch 37400, Training loss 1643860066304.0000, Validation loss 1486566326272.0000\n",
            "Epoch 37500, Training loss 1634951364608.0000, Validation loss 1478573948928.0000\n",
            "Epoch 37600, Training loss 1626052886528.0000, Validation loss 1470720114688.0000\n",
            "Epoch 37700, Training loss 1617218895872.0000, Validation loss 1462848716800.0000\n",
            "Epoch 37800, Training loss 1608458960896.0000, Validation loss 1455084929024.0000\n",
            "Epoch 37900, Training loss 1599796019200.0000, Validation loss 1447436877824.0000\n",
            "Epoch 38000, Training loss 1591237804032.0000, Validation loss 1439891980288.0000\n",
            "Epoch 38100, Training loss 1582774878208.0000, Validation loss 1432494145536.0000\n",
            "Epoch 38200, Training loss 1574396231680.0000, Validation loss 1425240752128.0000\n",
            "Epoch 38300, Training loss 1566110908416.0000, Validation loss 1418065215488.0000\n",
            "Epoch 38400, Training loss 1557936865280.0000, Validation loss 1411026911232.0000\n",
            "Epoch 38500, Training loss 1549882884096.0000, Validation loss 1404147073024.0000\n",
            "Epoch 38600, Training loss 1541945950208.0000, Validation loss 1397358723072.0000\n",
            "Epoch 38700, Training loss 1534069964800.0000, Validation loss 1390702886912.0000\n",
            "Epoch 38800, Training loss 1526322823168.0000, Validation loss 1384089387008.0000\n",
            "Epoch 38900, Training loss 1518668218368.0000, Validation loss 1377574846464.0000\n",
            "Epoch 39000, Training loss 1511108509696.0000, Validation loss 1371182727168.0000\n",
            "Epoch 39100, Training loss 1503652741120.0000, Validation loss 1364906999808.0000\n",
            "Epoch 39200, Training loss 1496255037440.0000, Validation loss 1358697332736.0000\n",
            "Epoch 39300, Training loss 1488920248320.0000, Validation loss 1352554381312.0000\n",
            "Epoch 39400, Training loss 1481654534144.0000, Validation loss 1346527035392.0000\n",
            "Epoch 39500, Training loss 1474481487872.0000, Validation loss 1340566011904.0000\n",
            "Epoch 39600, Training loss 1467395080192.0000, Validation loss 1334664364032.0000\n",
            "Epoch 39700, Training loss 1460396359680.0000, Validation loss 1328819077120.0000\n",
            "Epoch 39800, Training loss 1453503938560.0000, Validation loss 1323068686336.0000\n",
            "Epoch 39900, Training loss 1446734069760.0000, Validation loss 1317457494016.0000\n",
            "Epoch 40000, Training loss 1440092127232.0000, Validation loss 1312078299136.0000\n",
            "Epoch 40100, Training loss 1433552158720.0000, Validation loss 1306841055232.0000\n",
            "Epoch 40200, Training loss 1427104727040.0000, Validation loss 1301683896320.0000\n",
            "Epoch 40300, Training loss 1420737118208.0000, Validation loss 1296622813184.0000\n",
            "Epoch 40400, Training loss 1414454968320.0000, Validation loss 1291654529024.0000\n",
            "Epoch 40500, Training loss 1408238878720.0000, Validation loss 1286766460928.0000\n",
            "Epoch 40600, Training loss 1402036813824.0000, Validation loss 1281837367296.0000\n",
            "Epoch 40700, Training loss 1395947470848.0000, Validation loss 1277048913920.0000\n",
            "Epoch 40800, Training loss 1389952892928.0000, Validation loss 1272395726848.0000\n",
            "Epoch 40900, Training loss 1384046133248.0000, Validation loss 1267849887744.0000\n",
            "Epoch 41000, Training loss 1378173452288.0000, Validation loss 1263335112704.0000\n",
            "Epoch 41100, Training loss 1372385050624.0000, Validation loss 1258968055808.0000\n",
            "Epoch 41200, Training loss 1366679093248.0000, Validation loss 1254836797440.0000\n",
            "Epoch 41300, Training loss 1361065934848.0000, Validation loss 1250811838464.0000\n",
            "Epoch 41400, Training loss 1355568513024.0000, Validation loss 1246924242944.0000\n",
            "Epoch 41500, Training loss 1350185648128.0000, Validation loss 1243176632320.0000\n",
            "Epoch 41600, Training loss 1344895451136.0000, Validation loss 1239461658624.0000\n",
            "Epoch 41700, Training loss 1339700674560.0000, Validation loss 1235879198720.0000\n",
            "Epoch 41800, Training loss 1334587162624.0000, Validation loss 1232379576320.0000\n",
            "Epoch 41900, Training loss 1329516773376.0000, Validation loss 1229027672064.0000\n",
            "Epoch 42000, Training loss 1324508905472.0000, Validation loss 1225673539584.0000\n",
            "Epoch 42100, Training loss 1319602487296.0000, Validation loss 1222388744192.0000\n",
            "Epoch 42200, Training loss 1314792538112.0000, Validation loss 1219120070656.0000\n",
            "Epoch 42300, Training loss 1310043275264.0000, Validation loss 1216112492544.0000\n",
            "Epoch 42400, Training loss 1305335562240.0000, Validation loss 1213201907712.0000\n",
            "Epoch 42500, Training loss 1300706492416.0000, Validation loss 1210326974464.0000\n",
            "Epoch 42600, Training loss 1296180969472.0000, Validation loss 1207581278208.0000\n",
            "Epoch 42700, Training loss 1291725832192.0000, Validation loss 1205005189120.0000\n",
            "Epoch 42800, Training loss 1287354843136.0000, Validation loss 1202424643584.0000\n",
            "Epoch 42900, Training loss 1283084517376.0000, Validation loss 1199873064960.0000\n",
            "Epoch 43000, Training loss 1278899650560.0000, Validation loss 1197364346880.0000\n",
            "Epoch 43100, Training loss 1274793033728.0000, Validation loss 1194876076032.0000\n",
            "Epoch 43200, Training loss 1270769909760.0000, Validation loss 1192454127616.0000\n",
            "Epoch 43300, Training loss 1266824642560.0000, Validation loss 1190035193856.0000\n",
            "Epoch 43400, Training loss 1262967848960.0000, Validation loss 1187702112256.0000\n",
            "Epoch 43500, Training loss 1259195203584.0000, Validation loss 1185437188096.0000\n",
            "Epoch 43600, Training loss 1255496744960.0000, Validation loss 1183191662592.0000\n",
            "Epoch 43700, Training loss 1251878109184.0000, Validation loss 1181027794944.0000\n",
            "Epoch 43800, Training loss 1248311115776.0000, Validation loss 1178943356928.0000\n",
            "Epoch 43900, Training loss 1244782133248.0000, Validation loss 1176950800384.0000\n",
            "Epoch 44000, Training loss 1241304399872.0000, Validation loss 1174861119488.0000\n",
            "Epoch 44100, Training loss 1237875949568.0000, Validation loss 1172638400512.0000\n",
            "Epoch 44200, Training loss 1234503204864.0000, Validation loss 1170535743488.0000\n",
            "Epoch 44300, Training loss 1231181053952.0000, Validation loss 1168475291648.0000\n",
            "Epoch 44400, Training loss 1227903860736.0000, Validation loss 1166430044160.0000\n",
            "Epoch 44500, Training loss 1224683159552.0000, Validation loss 1164423987200.0000\n",
            "Epoch 44600, Training loss 1221516328960.0000, Validation loss 1162359341056.0000\n",
            "Epoch 44700, Training loss 1218391310336.0000, Validation loss 1160380678144.0000\n",
            "Epoch 44800, Training loss 1215313608704.0000, Validation loss 1158474498048.0000\n",
            "Epoch 44900, Training loss 1212281520128.0000, Validation loss 1156714201088.0000\n",
            "Epoch 45000, Training loss 1209316147200.0000, Validation loss 1154982608896.0000\n",
            "Epoch 45100, Training loss 1206400843776.0000, Validation loss 1153290862592.0000\n",
            "Epoch 45200, Training loss 1203532201984.0000, Validation loss 1151602917376.0000\n",
            "Epoch 45300, Training loss 1200731979776.0000, Validation loss 1149981556736.0000\n",
            "Epoch 45400, Training loss 1197982482432.0000, Validation loss 1148336603136.0000\n",
            "Epoch 45500, Training loss 1195272568832.0000, Validation loss 1146698858496.0000\n",
            "Epoch 45600, Training loss 1192598175744.0000, Validation loss 1145141985280.0000\n",
            "Epoch 45700, Training loss 1189959041024.0000, Validation loss 1143578165248.0000\n",
            "Epoch 45800, Training loss 1187366305792.0000, Validation loss 1142058123264.0000\n",
            "Epoch 45900, Training loss 1184830980096.0000, Validation loss 1140633370624.0000\n",
            "Epoch 46000, Training loss 1182348476416.0000, Validation loss 1139324223488.0000\n",
            "Epoch 46100, Training loss 1179890745344.0000, Validation loss 1137799200768.0000\n",
            "Epoch 46200, Training loss 1177465126912.0000, Validation loss 1136381657088.0000\n",
            "Epoch 46300, Training loss 1175086563328.0000, Validation loss 1134943666176.0000\n",
            "Epoch 46400, Training loss 1172750991360.0000, Validation loss 1133353762816.0000\n",
            "Epoch 46500, Training loss 1170440716288.0000, Validation loss 1131957321728.0000\n",
            "Epoch 46600, Training loss 1168194142208.0000, Validation loss 1130574118912.0000\n",
            "Epoch 46700, Training loss 1165994098688.0000, Validation loss 1129202581504.0000\n",
            "Epoch 46800, Training loss 1163846746112.0000, Validation loss 1127904182272.0000\n",
            "Epoch 46900, Training loss 1161758113792.0000, Validation loss 1126569082880.0000\n",
            "Epoch 47000, Training loss 1159697006592.0000, Validation loss 1125256527872.0000\n",
            "Epoch 47100, Training loss 1157610471424.0000, Validation loss 1123538436096.0000\n",
            "Epoch 47200, Training loss 1155557490688.0000, Validation loss 1122263629824.0000\n",
            "Epoch 47300, Training loss 1153553137664.0000, Validation loss 1121052917760.0000\n",
            "Epoch 47400, Training loss 1151563595776.0000, Validation loss 1119992938496.0000\n",
            "Epoch 47500, Training loss 1149606035456.0000, Validation loss 1119146475520.0000\n",
            "Epoch 47600, Training loss 1147700641792.0000, Validation loss 1118250205184.0000\n",
            "Epoch 47700, Training loss 1145826705408.0000, Validation loss 1117313302528.0000\n",
            "Epoch 47800, Training loss 1143992352768.0000, Validation loss 1116516122624.0000\n",
            "Epoch 47900, Training loss 1142202302464.0000, Validation loss 1115740176384.0000\n",
            "Epoch 48000, Training loss 1140426801152.0000, Validation loss 1114933035008.0000\n",
            "Epoch 48100, Training loss 1138673713152.0000, Validation loss 1114061275136.0000\n",
            "Epoch 48200, Training loss 1136949067776.0000, Validation loss 1113148489728.0000\n",
            "Epoch 48300, Training loss 1135229272064.0000, Validation loss 1112278958080.0000\n",
            "Epoch 48400, Training loss 1133477232640.0000, Validation loss 1111248470016.0000\n",
            "Epoch 48500, Training loss 1131757830144.0000, Validation loss 1110342631424.0000\n",
            "Epoch 48600, Training loss 1130082336768.0000, Validation loss 1109468381184.0000\n",
            "Epoch 48700, Training loss 1128428470272.0000, Validation loss 1108597014528.0000\n",
            "Epoch 48800, Training loss 1126795837440.0000, Validation loss 1107999326208.0000\n",
            "Epoch 48900, Training loss 1125189287936.0000, Validation loss 1107276201984.0000\n",
            "Epoch 49000, Training loss 1123606724608.0000, Validation loss 1106516508672.0000\n",
            "Epoch 49100, Training loss 1122035957760.0000, Validation loss 1105706090496.0000\n",
            "Epoch 49200, Training loss 1120472662016.0000, Validation loss 1104787931136.0000\n",
            "Epoch 49300, Training loss 1118895341568.0000, Validation loss 1103763996672.0000\n",
            "Epoch 49400, Training loss 1117322608640.0000, Validation loss 1102881488896.0000\n",
            "Epoch 49500, Training loss 1115751972864.0000, Validation loss 1101912473600.0000\n",
            "Epoch 49600, Training loss 1114193788928.0000, Validation loss 1101046874112.0000\n",
            "Epoch 49700, Training loss 1112679383040.0000, Validation loss 1100332269568.0000\n",
            "Epoch 49800, Training loss 1111195123712.0000, Validation loss 1099583193088.0000\n",
            "Epoch 49900, Training loss 1109686747136.0000, Validation loss 1098724016128.0000\n",
            "Epoch 50000, Training loss 1108223328256.0000, Validation loss 1097898917888.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = range(1, len(train_losses1) + 1)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot training losses\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_losses1, label='Training Loss 1a')\n",
        "plt.plot(epochs, train_losses2, label='Training Loss 1b')\n",
        "plt.title('Training Loss Comparison')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot validation losses\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, val_losses1, label='Validation Loss 1a')\n",
        "plt.plot(epochs, val_losses2, label='Validation Loss 1b')\n",
        "plt.title('Validation Loss Comparison')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "X2z_R9QcvjI7",
        "outputId": "41d7b200-6018-470e-f9ca-3ee244c52a2b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4dfA58mpKlUT"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}